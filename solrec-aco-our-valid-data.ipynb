{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vuhaidang2005/solrec-aco-our-valid-data?scriptVersionId=299922359\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"ae52d441","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:33:17.800637Z","iopub.status.busy":"2026-02-25T03:33:17.799662Z","iopub.status.idle":"2026-02-25T03:33:17.813034Z","shell.execute_reply":"2026-02-25T03:33:17.812334Z"},"papermill":{"duration":0.018714,"end_time":"2026-02-25T03:33:17.81417","exception":false,"start_time":"2026-02-25T03:33:17.795456","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/acorec\n"]}],"source":["%cd /kaggle/input/acorec\n"]},{"cell_type":"code","execution_count":2,"id":"bd6f8fca","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:33:17.818259Z","iopub.status.busy":"2026-02-25T03:33:17.818044Z","iopub.status.idle":"2026-02-25T03:35:11.112315Z","shell.execute_reply":"2026-02-25T03:35:11.110898Z"},"papermill":{"duration":113.298755,"end_time":"2026-02-25T03:35:11.114804","exception":false,"start_time":"2026-02-25T03:33:17.816049","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.3)\r\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\r\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.15.3)\r\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.7.2)\r\n","Collecting autogluon (from -r requirements.txt (line 6))\r\n","  Downloading autogluon-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2025.3.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2022.3.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2.4.1)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\r\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.2)\r\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\r\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.2)\r\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\r\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.59.0)\r\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\r\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (25.0)\r\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.3.0)\r\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\r\n","Collecting autogluon.core==1.5.0 (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_core-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting autogluon.features==1.5.0 (from autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_features-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Collecting autogluon.tabular==1.5.0 (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_tabular-1.5.0-py3-none-any.whl.metadata (16 kB)\r\n","Collecting autogluon.multimodal==1.5.0 (from autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_multimodal-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting autogluon.timeseries==1.5.0 (from autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_timeseries-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting scikit-learn (from -r requirements.txt (line 3))\r\n","  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n","Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.5)\r\n","Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.67.1)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.32.5)\r\n","Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.40.61)\r\n","Collecting autogluon.common==1.5.0 (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_common-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: ray<2.53,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.51.1)\r\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (19.0.1)\r\n","Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.2.7)\r\n","Collecting stevedore<5.5 (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\r\n","Requirement already satisfied: torch<2.10,>=2.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.0+cu124)\r\n","Collecting lightning<2.6,>=2.5.1 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: transformers<4.58,>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.53.3)\r\n","Requirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.9.0)\r\n","Collecting fsspec<=2025.3 (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n","Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\r\n","Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n","Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: torchvision<0.25.0,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.0+cu124)\r\n","Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.25.2)\r\n","Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3)\r\n","Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\r\n","Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.3.0)\r\n","Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\r\n","Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n","Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.9.2)\r\n","Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n","Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.1)\r\n","Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.6)\r\n","Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.18.0)\r\n","Requirement already satisfied: pytesseract<0.4,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.3.13)\r\n","Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Requirement already satisfied: pdf2image<1.19,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.0)\r\n","Collecting einx (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\r\n","Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.6.0)\r\n","Requirement already satisfied: huggingface_hub<1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.36.0)\r\n","Requirement already satisfied: xgboost<3.2,>=2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.3)\r\n","Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.8)\r\n","Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.8.5)\r\n","Collecting loguru (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n","Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.8.1)\r\n","Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.8.7)\r\n","Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\r\n","Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\r\n","Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\r\n","Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\r\n","Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n","Collecting fugue>=0.9.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading fugue-0.9.7-py3-none-any.whl.metadata (18 kB)\r\n","Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.11.0)\r\n","Collecting chronos-forecasting<2.4,>=2.2.2 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading chronos_forecasting-2.2.2-py3-none-any.whl.metadata (23 kB)\r\n","Requirement already satisfied: peft<0.18,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.16.0)\r\n","Requirement already satisfied: psutil<7.2.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (7.1.3)\r\n","Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.0.3)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\r\n","Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2025.3.0)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2022.3.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 1)) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.5.3)\r\n","Requirement already satisfied: botocore<1.41.0,>=1.40.61 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.40.61)\r\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.1)\r\n","Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.14.0)\r\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21)\r\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (5.24.1)\r\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.4.1)\r\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.0)\r\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.6.0)\r\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.70.18)\r\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (24.1.2)\r\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.0.7)\r\n","Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.8.15)\r\n","Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.0.2)\r\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.3)\r\n","Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.0)\r\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.2)\r\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.13.2)\r\n","Collecting triad>=1.0.1 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading triad-1.0.2-py3-none-any.whl.metadata (6.6 kB)\r\n","Collecting adagio>=0.2.6 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\r\n","Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.12.4)\r\n","Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.15.0)\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.20.0)\r\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.0)\r\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.0)\r\n","Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.10.9.7)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.3)\r\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (25.4.0)\r\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.4.1)\r\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.36.2)\r\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.26.0)\r\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.15.2)\r\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.5)\r\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.60.0)\r\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.5.0)\r\n","Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (5.2.0)\r\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (8.3.0)\r\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.11.3)\r\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.9.3)\r\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.6)\r\n","Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n","Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (14.2.0)\r\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.9.0)\r\n","Collecting click (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\r\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.1.2)\r\n","Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.33.0)\r\n","Collecting aiohttp_cors (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\r\n","Collecting colorful (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\r\n","Collecting py-spy>=0.2.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\r\n","Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.74.0)\r\n","Collecting opencensus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.60b1-py3-none-any.whl.metadata (2.1 kB)\r\n","Requirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.22.1)\r\n","Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (7.3.0.post1)\r\n","Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading virtualenv-20.39.0-py3-none-any.whl.metadata (3.5 kB)\r\n","Collecting tensorboardX>=1.9 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\r\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.4.4)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.11)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.10.5)\r\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.37.0)\r\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.6.11)\r\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4)\r\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.12)\r\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.5)\r\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.13)\r\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.11)\r\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.10)\r\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (8.3.6)\r\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.1.3)\r\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.1)\r\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.10)\r\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.1)\r\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.16.0)\r\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (75.2.0)\r\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.5.0)\r\n","Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.14.5)\r\n","Collecting pbr>=2.0.0 (from stevedore<5.5->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading pbr-7.0.3-py2.py3-none-any.whl.metadata (3.8 kB)\r\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.4.0)\r\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.8.2)\r\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.2)\r\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.3)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.6.2)\r\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.21.5)\r\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (12.4.127)\r\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.2.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.58,>=4.51.0->transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.2)\r\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.2.0)\r\n","Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.4.6)\r\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.1)\r\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.4.0)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.8.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (6.7.0)\r\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.1)\r\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.22.0)\r\n","INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\r\n","INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\r\n","  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\r\n","Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n","Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.13.4)\r\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.43.0)\r\n","Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.58b0)\r\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (8.7.0)\r\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.0)\r\n","Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.41.5)\r\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.2)\r\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.1)\r\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.1.5)\r\n","INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)\r\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.5.4)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.19.2)\r\n","Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\r\n","Collecting filelock (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\r\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.5.0)\r\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.1)\r\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.2)\r\n","Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n","Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\r\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.28.1)\r\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.23.0)\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\r\n","INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.60b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.1)\r\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.10.1)\r\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.41)\r\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (9.1.2)\r\n","Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.11/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.22.5)\r\n","Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.10)\r\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.70.0)\r\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.26.1)\r\n","Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.38.0)\r\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.1)\r\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.1.2)\r\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.2.3)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.7)\r\n","INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n","Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\r\n","  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\r\n","INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n","  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\r\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n","  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\r\n","  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\r\n","  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\r\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.7.1)\r\n","Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.2)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.9.1)\r\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.23.0)\r\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.6.1)\r\n","Downloading autogluon-1.5.0-py3-none-any.whl (5.9 kB)\r\n","Downloading autogluon_core-1.5.0-py3-none-any.whl (227 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_features-1.5.0-py3-none-any.whl (98 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_multimodal-1.5.0-py3-none-any.whl (452 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.1/452.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_tabular-1.5.0-py3-none-any.whl (515 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_timeseries-1.5.0-py3-none-any.whl (244 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_common-1.5.0-py3-none-any.whl (74 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading chronos_forecasting-2.2.2-py3-none-any.whl (72 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.8/285.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading fugue-0.9.7-py3-none-any.whl (281 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading lightning-2.5.6-py3-none-any.whl (827 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\r\n","Downloading click-8.3.1-py3-none-any.whl (108 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading pbr-7.0.3-py2.py3-none-any.whl (131 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading triad-1.0.2-py3-none-any.whl (59 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading virtualenv-20.39.0-py3-none-any.whl (5.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading filelock-3.24.3-py3-none-any.whl (24 kB)\r\n","Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\r\n","Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n","Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n","Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl (13 kB)\r\n","Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\r\n","Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\r\n","Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n","Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\r\n","Building wheels for collected packages: nvidia-ml-py3, seqeval\r\n","  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=e93587704552d1e0065f943de9c2e4169b9cf442672920db848654744cccc70a\r\n","  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\r\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=04d2ad57f85f8b33ca61e34bf019f83193285cafdc2e2fa6e75d4527cfbb90cb\r\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\r\n","Successfully built nvidia-ml-py3 seqeval\r\n","Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, toolz, pbr, ordered-set, openxlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, fsspec, filelock, dill, click, cachetools, virtualenv, stevedore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, opendatalab, nvidia-cusolver-cu12, jsonschema, aiohttp_cors, opencensus, opentelemetry-exporter-prometheus, triad, scikit-learn, autogluon.common, torchmetrics, autogluon.features, autogluon.core, adagio, window-ops, utilsforecast, thinc, tensorboardX, fugue, coreforecast, autogluon.tabular, statsforecast, mlforecast, lightning, gluonts, datasets, chronos-forecasting, timm, seqeval, pytorch-metric-learning, openmim, nlpaug, evaluate, einx, autogluon.timeseries, autogluon.multimodal, autogluon\r\n","  Attempting uninstall: toolz\r\n","    Found existing installation: toolz 1.1.0\r\n","    Uninstalling toolz-1.1.0:\r\n","      Successfully uninstalled toolz-1.1.0\r\n","  Attempting uninstall: nvidia-nvjitlink-cu12\r\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-curand-cu12\r\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n","  Attempting uninstall: nvidia-cufft-cu12\r\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cublas-cu12\r\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n","  Attempting uninstall: fsspec\r\n","    Found existing installation: fsspec 2025.10.0\r\n","    Uninstalling fsspec-2025.10.0:\r\n","      Successfully uninstalled fsspec-2025.10.0\r\n","  Attempting uninstall: filelock\r\n","    Found existing installation: filelock 3.20.0\r\n","    Uninstalling filelock-3.20.0:\r\n","      Successfully uninstalled filelock-3.20.0\r\n","  Attempting uninstall: dill\r\n","    Found existing installation: dill 0.4.0\r\n","    Uninstalling dill-0.4.0:\r\n","      Successfully uninstalled dill-0.4.0\r\n","  Attempting uninstall: click\r\n","    Found existing installation: click 8.3.0\r\n","    Uninstalling click-8.3.0:\r\n","      Successfully uninstalled click-8.3.0\r\n","  Attempting uninstall: cachetools\r\n","    Found existing installation: cachetools 6.2.1\r\n","    Uninstalling cachetools-6.2.1:\r\n","      Successfully uninstalled cachetools-6.2.1\r\n","  Attempting uninstall: nvidia-cusparse-cu12\r\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n","  Attempting uninstall: nvidia-cudnn-cu12\r\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n","  Attempting uninstall: multiprocess\r\n","    Found existing installation: multiprocess 0.70.18\r\n","    Uninstalling multiprocess-0.70.18:\r\n","      Successfully uninstalled multiprocess-0.70.18\r\n","  Attempting uninstall: nvidia-cusolver-cu12\r\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n","  Attempting uninstall: jsonschema\r\n","    Found existing installation: jsonschema 4.25.0\r\n","    Uninstalling jsonschema-4.25.0:\r\n","      Successfully uninstalled jsonschema-4.25.0\r\n","  Attempting uninstall: scikit-learn\r\n","    Found existing installation: scikit-learn 1.2.2\r\n","    Uninstalling scikit-learn-1.2.2:\r\n","      Successfully uninstalled scikit-learn-1.2.2\r\n","  Attempting uninstall: torchmetrics\r\n","    Found existing installation: torchmetrics 1.8.2\r\n","    Uninstalling torchmetrics-1.8.2:\r\n","      Successfully uninstalled torchmetrics-1.8.2\r\n","  Attempting uninstall: thinc\r\n","    Found existing installation: thinc 8.3.6\r\n","    Uninstalling thinc-8.3.6:\r\n","      Successfully uninstalled thinc-8.3.6\r\n","  Attempting uninstall: datasets\r\n","    Found existing installation: datasets 4.4.1\r\n","    Uninstalling datasets-4.4.1:\r\n","      Successfully uninstalled datasets-4.4.1\r\n","  Attempting uninstall: timm\r\n","    Found existing installation: timm 1.0.19\r\n","    Uninstalling timm-1.0.19:\r\n","      Successfully uninstalled timm-1.0.19\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n","category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n","preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\r\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n","sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n","bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n","libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n","gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 autogluon-1.5.0 autogluon.common-1.5.0 autogluon.core-1.5.0 autogluon.features-1.5.0 autogluon.multimodal-1.5.0 autogluon.tabular-1.5.0 autogluon.timeseries-1.5.0 cachetools-5.5.2 chronos-forecasting-2.2.2 click-8.3.1 colorful-0.5.8 coreforecast-0.0.16 datasets-4.0.0 dill-0.3.8 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 filelock-3.24.3 fsspec-2025.3.0 fugue-0.9.7 gluonts-0.16.2 jsonschema-4.23.0 lightning-2.5.6 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 opentelemetry-exporter-prometheus-0.58b0 openxlab-0.0.11 ordered-set-4.1.0 pbr-7.0.3 py-spy-0.4.1 pytorch-metric-learning-2.8.1 scikit-learn-1.7.2 seqeval-1.2.2 statsforecast-2.0.1 stevedore-5.4.1 tensorboardX-2.6.4 thinc-8.3.10 timm-1.0.3 toolz-0.12.1 torchmetrics-1.7.4 triad-1.0.2 utilsforecast-0.2.11 virtualenv-20.39.0 window-ops-0.0.15\r\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"id":"55d163ba","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:35:11.179201Z","iopub.status.busy":"2026-02-25T03:35:11.178134Z","iopub.status.idle":"2026-02-25T04:13:59.605337Z","shell.execute_reply":"2026-02-25T04:13:59.604074Z"},"papermill":{"duration":2328.459884,"end_time":"2026-02-25T04:13:59.60745","exception":false,"start_time":"2026-02-25T03:35:11.147566","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded performance matrix: /kaggle/input/acorec/aco/training_performance_matrix_autogluon.csv\r\n","Loaded metafeatures: /kaggle/input/acorec/aco/dataset_feats.csv\r\n","Loaded pipeline configs: /kaggle/input/acorec/aco/pipeline_configs.json\r\n","Aligned datasets: 29\r\n","\r\n","=== Dataset 862 (1/2) ===\r\n","Loaded dataset 862\r\n","  Shape: (87, 10)\r\n","  Task: classification\r\n","  Target classes: 2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","ACO Iter 1/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 3/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       29.58 GB / 31.35 GB (94.4%)\r\n","Disk Space Avail:   1385.25 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\r\n","2026-02-25 03:35:58,518\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\r\n","/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\r\n","  warnings.warn(\r\n","Warning: Not enough time to fit DyStack! Skipping...\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t10s\t = DyStack   runtime |\t20s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 20s\r\n","AutoGluon will save models to \"/tmp/autogluon_7d7b65302e90484f8e1ac3c81f85523c\"\r\n","Train Data Rows:    52\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 13.49s of the 20.01s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6346\t = Validation score   (accuracy)\r\n","\t10.47s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.47s of the 6.99s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\u001b[36m(_ray_fit pid=814)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\r\n","\u001b[36m(_ray_fit pid=814)\u001b[0m \t[1]\tvalid_set's binary_error: 0.5\r\n","\t0.5962\t = Validation score   (accuracy)\r\n","\t6.74s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 20.24s of the -2.55s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.4 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6346\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 20.24s of the -2.68s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.4 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6346\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 22.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 465.4 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (52 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_7d7b65302e90484f8e1ac3c81f85523c\")\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5294\r\n","Ordering Iter 1/10 quick AutoGluon: 0.5294\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 2/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 3/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  2. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  3. {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  4. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  5. {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.71 GB / 31.35 GB (88.4%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_539b7129861e441ab0fe8353e470668a/ds_sub_fit/sub_fit_ho\"\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Running DyStack sub-fit ...\r\n","\u001b[36m(_ray_fit pid=816)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\r\n","\u001b[36m(_ray_fit pid=816)\u001b[0m \t[1]\tvalid_set's binary_error: 0.5\u001b[32m [repeated 3x across cluster]\u001b[0m\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Beginning AutoGluon training ... Time limit = 7s\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m AutoGluon will save models to \"/tmp/autogluon_539b7129861e441ab0fe8353e470668a/ds_sub_fit/sub_fit_ho\"\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Train Data Rows:    46\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Train Data Columns: 12\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Label Column:       target\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Problem Type:       binary\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Preprocessing data ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Using Feature Generators to preprocess the data ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting IdentityFeatureGenerator...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Data preprocessing and feature engineering runtime = 0.01s ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m User-specified model hyperparameters to be fit:\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m {\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m }\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4.66s of the 6.98s of remaining time.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.5435\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t6.84s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.0s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 6.99s of the -4.92s of remaining time.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.2 GB\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.5435\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.0s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.0s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 6.99s of the -5.03s of remaining time.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.2 GB\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.5435\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.0s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t0.0s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m AutoGluon training complete, total runtime = 12.04s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2541.3 rows/s (10 batch size)\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (46 rows).\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m \t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_539b7129861e441ab0fe8353e470668a/ds_sub_fit/sub_fit_ho\")\r\n","\u001b[36m(_dystack pid=1078)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.543478    accuracy        1.759818       0.003730  6.836931                 1.759818                0.003730           6.836931            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.543478    accuracy        1.760993       0.004904  6.841201                 0.001175                0.001174           0.004269            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.543478    accuracy        1.761828       0.004672  6.840275                 0.002010                0.000942           0.003343            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t17s\t = DyStack   runtime |\t13s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 13s\r\n","AutoGluon will save models to \"/tmp/autogluon_539b7129861e441ab0fe8353e470668a\"\r\n","Train Data Rows:    52\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 8.61s of the 12.91s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t6.18s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 12.91s of the 3.48s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3.47s of the 3.46s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6731\t = Validation score   (accuracy)\r\n","\t6.26s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 12.91s of the -5.91s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 18.84s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2517.1 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (52 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_539b7129861e441ab0fe8353e470668a\")\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","Ordering Iter 2/10 quick AutoGluon: 0.7059\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 1/10 — best: 0.7647 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 2/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 3/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.70 GB / 31.35 GB (88.4%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_7d5f03874e924d97a8a1fa83260bb52d/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.543478    accuracy        1.669172       0.004487  6.687819                 1.669172                0.004487           6.687819            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.543478    accuracy        1.670188       0.005407  6.691244                 0.001016                0.000920           0.003425            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.543478    accuracy        1.670914       0.005410  6.691146                 0.001742                0.000923           0.003327            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_7d5f03874e924d97a8a1fa83260bb52d\"\r\n","Train Data Rows:    52\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.49s of the 14.23s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t6.27s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.18s of the 4.92s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.5385\t = Validation score   (accuracy)\r\n","\t6.23s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.24s of the -4.24s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.24s of the -4.34s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 18.6s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2408.9 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (52 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_7d5f03874e924d97a8a1fa83260bb52d\")\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","Ordering Iter 3/10 quick AutoGluon: 0.7059\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 1/10 — best: 0.8235 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 5/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  2. {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  3. {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  4. {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  5. {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.70 GB / 31.35 GB (88.4%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_d5c6471815ec4923aee6b703de62b678/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.555556    accuracy        1.769733       0.004121  6.421930                 1.769733                0.004121           6.421930            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.555556    accuracy        1.770882       0.005027  6.426119                 0.001149                0.000906           0.004189            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.555556    accuracy        1.771651       0.005006  6.425150                 0.001918                0.000885           0.003221            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_d5c6471815ec4923aee6b703de62b678\"\r\n","Train Data Rows:    51\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.50s of the 14.24s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t6.77s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.25s of the 4.54s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.52s of the 4.51s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6275\t = Validation score   (accuracy)\r\n","\t6.38s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.25s of the -4.95s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2455.6 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (51 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_d5c6471815ec4923aee6b703de62b678\")\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","Ordering Iter 4/10 quick AutoGluon: 0.7059\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","ACO Iter 1/10 — best: 0.7647 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 3/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.70 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_7d83d942ce9f44129a67039853c18099/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.543478    accuracy        1.769087       0.003908  6.487667                 1.769087                0.003908           6.487667            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.543478    accuracy        1.770125       0.004885  6.491188                 0.001039                0.000977           0.003520            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.543478    accuracy        1.770911       0.004860  6.492011                 0.001824                0.000952           0.004344            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_7d83d942ce9f44129a67039853c18099\"\r\n","Train Data Rows:    52\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.44s of the 14.16s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t6.88s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.17s of the 4.25s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.24s of the 4.23s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6731\t = Validation score   (accuracy)\r\n","\t6.76s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.17s of the -5.50s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.75\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.69s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2400.6 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (52 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_7d83d942ce9f44129a67039853c18099\")\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","Ordering Iter 5/10 quick AutoGluon: 0.7059\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","ACO Iter 2/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8824\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  2. {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  3. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  4. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.70 GB / 31.35 GB (88.4%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_ab7ef47f156241ea837c8361f0f34fbf/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.545455    accuracy        1.795081       0.004443  6.579936                 1.795081                0.004443           6.579936            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.545455    accuracy        1.796300       0.005474  6.583807                 0.001219                0.001031           0.003870            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.545455    accuracy        1.797052       0.005413  6.583272                 0.001970                0.000970           0.003336            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_ab7ef47f156241ea837c8361f0f34fbf\"\r\n","Train Data Rows:    50\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.38s of the 14.06s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.58\t = Validation score   (accuracy)\r\n","\t6.73s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.07s of the 4.35s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.58\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.34s of the 4.33s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.7\t = Validation score   (accuracy)\r\n","\t6.54s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.07s of the -5.19s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\r\n","\t0.7\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.28s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1051.8 rows/s (10 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (50 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_ab7ef47f156241ea837c8361f0f34fbf\")\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5294\r\n","Ordering Iter 6/10 quick AutoGluon: 0.5294\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 1/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 2/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4706\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 3/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4706\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_f4dad018ba0d4241b40ea8a7e494f238/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.555556    accuracy        1.827965       0.004637  6.709829                 1.827965                0.004637           6.709829            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.555556    accuracy        1.829231       0.005641  6.713587                 0.001266                0.001004           0.003758            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.555556    accuracy        1.830123       0.005641  6.713546                 0.002158                0.001004           0.003717            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_f4dad018ba0d4241b40ea8a7e494f238\"\r\n","Train Data Rows:    51\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.04s of the 13.56s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t6.65s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 13.57s of the 3.84s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3.83s of the 3.82s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6275\t = Validation score   (accuracy)\r\n","\t6.59s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 13.57s of the -6.20s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2420.3 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (51 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_f4dad018ba0d4241b40ea8a7e494f238\")\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","Ordering Iter 7/10 quick AutoGluon: 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4706\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 1/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4706\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 3/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 5/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 6/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_96415e6832ee402ca9c52007b2c9deae/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.555556    accuracy        1.807669       0.005012  6.354228                 1.807669                0.005012           6.354228            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.555556    accuracy        1.808697       0.005899  6.357686                 0.001028                0.000888           0.003458            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.555556    accuracy        1.809441       0.005827  6.357426                 0.001772                0.000816           0.003198            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_96415e6832ee402ca9c52007b2c9deae\"\r\n","Train Data Rows:    51\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.31s of the 13.96s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t6.44s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 13.97s of the 4.51s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.50s of the 4.48s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.7059\t = Validation score   (accuracy)\r\n","\t6.53s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 13.97s of the -5.18s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\r\n","\t0.7059\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.17s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1112.9 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (51 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_96415e6832ee402ca9c52007b2c9deae\")\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7647\r\n","Ordering Iter 8/10 quick AutoGluon: 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 1/10 — best: 0.8235 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'zscore', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4706\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","ACO Iter 3/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5882\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 4/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 5/10 — best: 0.8235 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 6/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 7/10 — best: 0.8235 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 8/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4706\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 9/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8235\r\n","ACO Iter 10/10 — best: 0.8235 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8235\r\n","  2. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8235\r\n","  3. {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8235\r\n","  4. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8235\r\n","  5. {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8235\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_8d3713ba05a9497b8f6c9752c3fe6da9/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.553191    accuracy        1.836385       0.004127  6.227723                 1.836385                0.004127           6.227723            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.553191    accuracy        1.837415       0.004972  6.231010                 0.001030                0.000845           0.003287            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.553191    accuracy        1.838204       0.005030  6.230957                 0.001820                0.000903           0.003234            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_8d3713ba05a9497b8f6c9752c3fe6da9\"\r\n","Train Data Rows:    53\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.57s of the 14.35s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6415\t = Validation score   (accuracy)\r\n","\t6.16s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.48s of the 5.26s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.5849\t = Validation score   (accuracy)\r\n","\t6.44s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.36s of the -4.30s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6415\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.36s of the -4.45s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6415\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 18.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2658.4 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (53 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_8d3713ba05a9497b8f6c9752c3fe6da9\")\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7059\r\n","Ordering Iter 9/10 quick AutoGluon: 0.7059\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","ACO Iter 1/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 2/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 3/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4118\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","ACO Iter 4/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 5/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4706\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","ACO Iter 6/10 — best: 0.8235 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5882\r\n","ACO Iter 7/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 8/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7059\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","ACO Iter 9/10 — best: 0.8824 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8235\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8824\r\n","ACO Iter 10/10 — best: 0.8824 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  2. {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  3. {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  4. {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","  5. {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8824\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_9f1c25582e9341018e5e8a86a40c7f3a/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.5   0.545455    accuracy        1.813691       0.007260  6.481943                 1.813691                0.007260           6.481943            1       True          1\r\n","1  WeightedEnsemble_L3            0.5   0.545455    accuracy        1.815058       0.008183  6.485645                 0.001368                0.000923           0.003703            3       True          3\r\n","2  WeightedEnsemble_L2            0.5   0.545455    accuracy        1.815845       0.008426  6.485990                 0.002154                0.001166           0.004048            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_9f1c25582e9341018e5e8a86a40c7f3a\"\r\n","Train Data Rows:    50\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.31s of the 13.97s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.54\t = Validation score   (accuracy)\r\n","\t6.64s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 13.98s of the 4.32s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.54\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4.31s of the 4.30s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.66\t = Validation score   (accuracy)\r\n","\t6.55s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 13.98s of the -5.34s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\r\n","\t0.66\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.33s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1096.1 rows/s (10 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (50 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_9f1c25582e9341018e5e8a86a40c7f3a\")\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7647\r\n","Ordering Iter 10/10 quick AutoGluon: 0.7647\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.49 GB / 31.35 GB (87.7%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_37378575a7174acaa2a63497f0dab7fa/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0   RandomForestGini_BAG_L1       1.000000   0.511111    accuracy        0.069694       0.075368   0.722327                 0.069694                0.075368           0.722327            1       True          3\r\n","1     ExtraTreesEntr_BAG_L1       0.833333   0.466667    accuracy        0.066684       0.067839   0.622140                 0.066684                0.067839           0.622140            1       True          7\r\n","2     ExtraTreesGini_BAG_L1       0.833333   0.422222    accuracy        0.068431       0.068409   0.698479                 0.068431                0.068409           0.698479            1       True          6\r\n","3   RandomForestEntr_BAG_L1       0.833333   0.466667    accuracy        0.071115       0.071320   0.678116                 0.071115                0.071320           0.678116            1       True          4\r\n","4           CatBoost_BAG_L1       0.666667   0.688889    accuracy        0.280076       0.007859   4.388304                 0.280076                0.007859           4.388304            1       True          5\r\n","5    NeuralNetFastAI_BAG_L1       0.666667   0.622222    accuracy        0.709290       0.126089  22.778646                 0.709290                0.126089          22.778646            1       True          8\r\n","6       WeightedEnsemble_L3       0.666667   0.711111    accuracy        1.904350       0.012910  10.667929                 0.001230                0.000810           0.044140            3       True         12\r\n","7       WeightedEnsemble_L2       0.666667   0.711111    accuracy        1.904667       0.013214  10.744004                 0.001547                0.001113           0.120215            2       True          9\r\n","8           LightGBM_BAG_L1       0.500000   0.555556    accuracy        0.003529       0.003645   6.244303                 0.003529                0.003645           6.244303            1       True          2\r\n","9         LightGBMXT_BAG_L1       0.500000   0.555556    accuracy        1.623044       0.004241   6.235486                 1.623044                0.004241           6.235486            1       True          1\r\n","10          LightGBM_BAG_L2       0.500000   0.555556    accuracy        2.753689       0.291715  41.725590                 0.004901                0.010319           6.978687            2       True         11\r\n","11        LightGBMXT_BAG_L2       0.500000   0.555556    accuracy        2.754165       0.293206  41.757939                 0.005377                0.011810           7.011036            2       True         10\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t85s\t = DyStack   runtime |\t215s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 215s\r\n","AutoGluon will save models to \"/tmp/autogluon_37378575a7174acaa2a63497f0dab7fa\"\r\n","Train Data Rows:    51\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 143.24s of the 214.90s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t6.64s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 133.55s of the 205.21s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t6.42s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 124.00s of the 195.66s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5294\t = Validation score   (accuracy)\r\n","\t0.84s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 123.06s of the 194.73s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5686\t = Validation score   (accuracy)\r\n","\t0.84s\t = Training   runtime\r\n","\t0.07s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 122.13s of the 193.79s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.38%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t3.82s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 115.38s of the 187.04s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.549\t = Validation score   (accuracy)\r\n","\t0.81s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 114.47s of the 186.13s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5294\t = Validation score   (accuracy)\r\n","\t0.74s\t = Training   runtime\r\n","\t0.07s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 113.63s of the 185.30s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.7255\t = Validation score   (accuracy)\r\n","\t11.13s\t = Training   runtime\r\n","\t0.04s\t = Validation runtime\r\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 99.70s of the 171.36s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\r\n","\t0.7843\t = Validation score   (accuracy)\r\n","\t2.43s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 94.05s of the 165.71s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t14.97s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 76.00s of the 147.66s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.25%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t6.66s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 66.12s of the 137.79s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.40%)\r\n","\t0.7647\t = Validation score   (accuracy)\r\n","\t3.69s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 59.36s of the 131.02s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t10.39s\t = Training   runtime\r\n","\t0.07s\t = Validation runtime\r\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 46.11s of the 117.77s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t6.97s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 35.96s of the 107.63s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t10.53s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 22.36s of the 94.02s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.44%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t5.35s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 13.75s of the 85.41s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\r\n","\t0.549\t = Validation score   (accuracy)\r\n","\t7.02s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 3.43s of the 75.10s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 214.91s of the 66.90s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.2 GB\r\n","\tEnsemble Weights: {'LightGBM_r131_BAG_L1': 1.0}\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t0.07s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 66.82s of the 66.79s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t6.79s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L2 ... Training model for up to 56.87s of the 56.84s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t6.79s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 46.75s of the 46.72s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6275\t = Validation score   (accuracy)\r\n","\t0.83s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 45.80s of the 45.77s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6275\t = Validation score   (accuracy)\r\n","\t0.87s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L2 ... Training model for up to 44.83s of the 44.81s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.44%)\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t4.15s\t = Training   runtime\r\n","\t0.03s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 37.88s of the 37.85s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6275\t = Validation score   (accuracy)\r\n","\t0.82s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 36.94s of the 36.91s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5882\t = Validation score   (accuracy)\r\n","\t0.79s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 36.06s of the 36.03s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.8627\t = Validation score   (accuracy)\r\n","\t10.92s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: XGBoost_BAG_L2 ... Training model for up to 21.35s of the 21.33s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t2.68s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 15.35s of the 15.32s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t11.25s\t = Training   runtime\r\n","\t0.06s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 214.91s of the 0.49s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.5 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 1.0}\r\n","\t0.8627\t = Validation score   (accuracy)\r\n","\t0.07s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 214.51s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 44.8 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (51 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_37378575a7174acaa2a63497f0dab7fa\")\r\n","    ! {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} hit XGBoost compatibility issue, retrying without XGB models\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       28.80 GB / 31.35 GB (91.9%)\r\n","Disk Space Avail:   1385.19 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_eb9ef0979b6b40ee913c5915dfc79146/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0   RandomForestGini_BAG_L1       1.000000   0.511111    accuracy        0.079665       0.073518   0.806833                 0.079665                0.073518           0.806833            1       True          3\r\n","1   RandomForestEntr_BAG_L1       0.833333   0.466667    accuracy        0.067251       0.070098   0.772548                 0.067251                0.070098           0.772548            1       True          4\r\n","2     ExtraTreesEntr_BAG_L1       0.833333   0.466667    accuracy        0.067606       0.106215   0.742830                 0.067606                0.106215           0.742830            1       True          7\r\n","3     ExtraTreesGini_BAG_L1       0.833333   0.422222    accuracy        0.070179       0.077603   0.749740                 0.070179                0.077603           0.749740            1       True          6\r\n","4   RandomForestEntr_BAG_L2       0.833333   0.600000    accuracy        3.039124       0.312393  23.818183                 0.070446                0.069070           0.728430            2       True         13\r\n","5           CatBoost_BAG_L1       0.666667   0.688889    accuracy        0.321284       0.009454   4.013214                 0.321284                0.009454           4.013214            1       True          5\r\n","6    NeuralNetFastAI_BAG_L1       0.666667   0.622222    accuracy        0.822963       0.049951  10.759361                 0.822963                0.049951          10.759361            1       True          8\r\n","7       WeightedEnsemble_L2       0.666667   0.711111    accuracy        2.001058       0.014917  10.856847                 0.002613                0.001279           0.076118            2       True          9\r\n","8   RandomForestGini_BAG_L2       0.666667   0.711111    accuracy        3.044835       0.327373  23.891784                 0.076157                0.084051           0.802031            2       True         12\r\n","9       WeightedEnsemble_L3       0.666667   0.733333    accuracy        3.048023       0.328182  23.949560                 0.003188                0.000808           0.057776            3       True         14\r\n","10          LightGBM_BAG_L1       0.500000   0.555556    accuracy        0.003747       0.006007   6.523636                 0.003747                0.006007           6.523636            1       True          2\r\n","11        LightGBMXT_BAG_L1       0.500000   0.555556    accuracy        1.677161       0.004184   6.767515                 1.677161                0.004184           6.767515            1       True          1\r\n","12          LightGBM_BAG_L2       0.500000   0.555556    accuracy        2.977033       0.258164  29.677145                 0.008354                0.014842           6.587392            2       True         11\r\n","13        LightGBMXT_BAG_L2       0.500000   0.555556    accuracy        2.977455       0.255007  29.969483                 0.008776                0.011684           6.879730            2       True         10\r\n","\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\r\n","\t84s\t = DyStack   runtime |\t216s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=0.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\r\n","Beginning AutoGluon training ... Time limit = 216s\r\n","AutoGluon will save models to \"/tmp/autogluon_eb9ef0979b6b40ee913c5915dfc79146\"\r\n","Train Data Rows:    51\r\n","Train Data Columns: 12\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","Excluded models: ['XGB'] (Specified by `excluded_model_types`)\r\n","Fitting 98 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 216.22s of the 216.21s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t7.07s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 205.85s of the 205.84s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t7.76s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 194.90s of the 194.90s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5294\t = Validation score   (accuracy)\r\n","\t0.95s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 193.82s of the 193.81s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5686\t = Validation score   (accuracy)\r\n","\t0.95s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 192.77s of the 192.76s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.33%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t4.51s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 185.23s of the 185.22s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.549\t = Validation score   (accuracy)\r\n","\t0.92s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 184.17s of the 184.17s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.5294\t = Validation score   (accuracy)\r\n","\t0.92s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 183.15s of the 183.15s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.7255\t = Validation score   (accuracy)\r\n","\t11.89s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 168.09s of the 168.08s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t11.07s\t = Training   runtime\r\n","\t0.04s\t = Validation runtime\r\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 153.49s of the 153.48s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.24%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t7.47s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 142.49s of the 142.48s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.34%)\r\n","\t0.7647\t = Validation score   (accuracy)\r\n","\t4.43s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 134.82s of the 134.81s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6667\t = Validation score   (accuracy)\r\n","\t11.56s\t = Training   runtime\r\n","\t0.06s\t = Validation runtime\r\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 119.77s of the 119.76s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t7.02s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 109.07s of the 109.06s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t11.4s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 94.21s of the 94.20s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.39%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t5.58s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 84.96s of the 84.96s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.03%)\r\n","\t0.549\t = Validation score   (accuracy)\r\n","\t7.59s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 73.87s of the 73.86s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.7255\t = Validation score   (accuracy)\r\n","\t11.33s\t = Training   runtime\r\n","\t0.04s\t = Validation runtime\r\n","Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 59.16s of the 59.16s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.549\t = Validation score   (accuracy)\r\n","\t0.88s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 58.19s of the 58.19s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.32%)\r\n","\t0.7843\t = Validation score   (accuracy)\r\n","\t3.91s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 50.97s of the 50.96s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t10.84s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 37.04s of the 37.03s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.39%)\r\n","\t0.7451\t = Validation score   (accuracy)\r\n","\t4.52s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 28.99s of the 28.98s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6471\t = Validation score   (accuracy)\r\n","\t1.63s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 27.26s of the 27.25s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.24%)\r\n","\t0.7647\t = Validation score   (accuracy)\r\n","\t7.08s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 17.01s of the 17.00s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6863\t = Validation score   (accuracy)\r\n","\t11.08s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 2.52s of the 2.51s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\tTime limit exceeded... Skipping NeuralNetTorch_r30_BAG_L1.\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 216.22s of the -6.48s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.3 GB\r\n","\tEnsemble Weights: {'LightGBM_r131_BAG_L1': 1.0}\r\n","\t0.8039\t = Validation score   (accuracy)\r\n","\t0.07s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 222.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2006.9 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (51 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_eb9ef0979b6b40ee913c5915dfc79146\")\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6471\r\n","\r\n","Final recommendation\r\n","  Dataset: 862\r\n","  Pipeline: {imputation=mean, scaling=minmax, encoding=onehot, feature_selection=mutual_info, outlier_removal=zscore, dimensionality_reduction=svd, step_order=['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}\r\n","  Proxy score: 0.7647\r\n","  Final eval (autogluon): 0.6471\r\n","  Optimizer: aco\r\n","  Ordering search: strategy=heuristic orders=10\r\n","  Saved recommendation: /kaggle/working/dataset_862/recommendation.json\r\n","  Saved ACO history: /kaggle/working/dataset_862/aco_history.csv\r\n","  Saved ACO plot: /kaggle/working/dataset_862/aco_progress.png\r\n","  Elapsed seconds: 1156.21\r\n","2026-02-25 03:54:33,494 | INFO | __main__ | Saved recommendation to /kaggle/working/dataset_862/recommendation.json\r\n","\r\n","=== Dataset 40663 (2/2) ===\r\n","Loaded dataset 40663\r\n","  Shape: (399, 32)\r\n","  Task: classification\r\n","  Target classes: 5\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 1/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","ACO Iter 2/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       21.27 GB / 31.35 GB (67.9%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_effa819cb5d14a79b99bca9fd36c0b5d/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t21s\t = DyStack   runtime |\t9s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 9s\r\n","AutoGluon will save models to \"/tmp/autogluon_effa819cb5d14a79b99bca9fd36c0b5d\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6.24s of the 9.36s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.69\t = Validation score   (accuracy)\r\n","\t19.61s\t = Training   runtime\r\n","\t0.13s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 9.37s of the -14.31s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.69\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 9.37s of the -14.42s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.69\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 23.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 229.5 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_effa819cb5d14a79b99bca9fd36c0b5d\")\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","Ordering Iter 1/10 quick AutoGluon: 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 0.5696 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4810\r\n","ACO Iter 2/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4177\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","ACO Iter 3/10 — best: 0.5823 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4177\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  2. {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  3. {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  4. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  5. {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_348f41d710b440e5859dc3c0ac527178/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.615385   0.669951    accuracy        1.381613       0.082167  16.601888                 1.381613                0.082167          16.601888            1       True          1\r\n","1     WeightedEnsemble_L3       0.615385   0.669951    accuracy        1.383880       0.087533  16.614336                 0.002267                0.005367           0.012449            3       True          3\r\n","2     WeightedEnsemble_L2       0.615385   0.669951    accuracy        1.384181       0.083521  16.607309                 0.002568                0.001354           0.005421            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t27s\t = DyStack   runtime |\t3s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 3s\r\n","AutoGluon will save models to \"/tmp/autogluon_348f41d710b440e5859dc3c0ac527178\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.13s of the 3.18s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t15.22s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 3.19s of the -15.35s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 3.19s of the -15.47s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 18.69s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 282.9 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_348f41d710b440e5859dc3c0ac527178\")\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5949\r\n","Ordering Iter 2/10 quick AutoGluon: 0.5949\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4051\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 1/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 2/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_62e94f5701fe4ece86526b023ddcd3cd/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.666667    0.67757    accuracy        1.603718       0.095857  15.428069                 1.603718                0.095857          15.428069            1       True          1\r\n","1     WeightedEnsemble_L3       0.666667    0.67757    accuracy        1.605136       0.100438  15.442290                 0.001418                0.004581           0.014221            3       True          3\r\n","2     WeightedEnsemble_L2       0.666667    0.67757    accuracy        1.605686       0.097065  15.433403                 0.001967                0.001208           0.005334            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_62e94f5701fe4ece86526b023ddcd3cd\"\r\n","Train Data Rows:    241\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.84s of the 4.25s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6722\t = Validation score   (accuracy)\r\n","\t15.96s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.26s of the -15.20s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6722\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.26s of the -15.31s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6722\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.6s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 281.6 rows/s (31 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_62e94f5701fe4ece86526b023ddcd3cd\")\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","Ordering Iter 3/10 quick AutoGluon: 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","ACO Iter 1/10 — best: 0.5443 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4810\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4810\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","ACO Iter 2/10 — best: 0.5316 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.5696 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4304\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  2. {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  3. {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  4. {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  5. {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.46 GB / 31.35 GB (87.6%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_9384e78e441a4a0aaf9139a03e175336/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.576923   0.689655    accuracy        1.480420       0.109828  15.371484                 1.480420                0.109828          15.371484            1       True          1\r\n","1     WeightedEnsemble_L3       0.576923   0.689655    accuracy        1.481478       0.111118  15.375729                 0.001058                0.001290           0.004245            3       True          3\r\n","2     WeightedEnsemble_L2       0.576923   0.689655    accuracy        1.482019       0.110914  15.375882                 0.001599                0.001087           0.004398            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_9384e78e441a4a0aaf9139a03e175336\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.81s of the 4.21s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t16.51s\t = Training   runtime\r\n","\t0.18s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.22s of the -15.52s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.22s of the -15.64s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 157.8 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_9384e78e441a4a0aaf9139a03e175336\")\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","Ordering Iter 4/10 quick AutoGluon: 0.5696\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 1/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4557\r\n","ACO Iter 2/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_bd5e81caacaa4884bcbaf976de30448d/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.576923   0.694581    accuracy        1.672772       0.081875  15.388950                 1.672772                0.081875          15.388950            1       True          1\r\n","1     WeightedEnsemble_L3       0.576923   0.694581    accuracy        1.674365       0.083621  15.395099                 0.001593                0.001746           0.006148            3       True          3\r\n","2     WeightedEnsemble_L2       0.576923   0.694581    accuracy        1.675217       0.083295  15.394766                 0.002445                0.001420           0.005816            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_bd5e81caacaa4884bcbaf976de30448d\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.91s of the 4.36s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6943\t = Validation score   (accuracy)\r\n","\t16.26s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.37s of the -15.39s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6943\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.37s of the -15.50s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6943\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.9s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 352.3 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_bd5e81caacaa4884bcbaf976de30448d\")\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","Ordering Iter 5/10 quick AutoGluon: 0.5570\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 0.5696 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4810\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","ACO Iter 2/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.5063 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  2. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  3. {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  4. {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  5. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.44 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_6c5b859cf621441fac3d8275ca6360db/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.576923   0.689655    accuracy        1.580402       0.075993  16.036067                 1.580402                0.075993          16.036067            1       True          1\r\n","1     WeightedEnsemble_L3       0.576923   0.689655    accuracy        1.581984       0.077201  16.041501                 0.001582                0.001208           0.005434            3       True          3\r\n","2     WeightedEnsemble_L2       0.576923   0.689655    accuracy        1.582863       0.077053  16.041014                 0.002461                0.001060           0.004947            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t27s\t = DyStack   runtime |\t3s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 3s\r\n","AutoGluon will save models to \"/tmp/autogluon_6c5b859cf621441fac3d8275ca6360db\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.15s of the 3.22s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6681\t = Validation score   (accuracy)\r\n","\t16.41s\t = Training   runtime\r\n","\t0.16s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 3.23s of the -16.73s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6681\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 3.23s of the -16.85s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6681\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 20.12s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 177.1 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_6c5b859cf621441fac3d8275ca6360db\")\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","Ordering Iter 6/10 quick AutoGluon: 0.5823\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4051\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4051\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 1/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","ACO Iter 2/10 — best: 0.5823 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4810\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_885141c4d86141beb2a8ae5f04ec0318/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.538462   0.679803    accuracy        1.532806       0.091492  15.907173                 1.532806                0.091492          15.907173            1       True          1\r\n","1     WeightedEnsemble_L3       0.538462   0.679803    accuracy        1.534252       0.092625  15.911351                 0.001446                0.001133           0.004178            3       True          3\r\n","2     WeightedEnsemble_L2       0.538462   0.679803    accuracy        1.534793       0.093669  15.915583                 0.001987                0.002177           0.008410            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_885141c4d86141beb2a8ae5f04ec0318\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.34s of the 3.50s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t15.53s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 3.51s of the -15.51s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 3.51s of the -15.63s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6769\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 19.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 324.9 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_885141c4d86141beb2a8ae5f04ec0318\")\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","Ordering Iter 7/10 quick AutoGluon: 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","ACO Iter 1/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","ACO Iter 2/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.3924\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5190\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4430\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5823\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5570\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.4430\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.45 GB / 31.35 GB (87.6%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_cc2a6c0f30a049edb7dbd57748295f79/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.576923   0.694581    accuracy        1.513979       0.136021  15.633122                 1.513979                0.136021          15.633122            1       True          1\r\n","1     WeightedEnsemble_L3       0.576923   0.694581    accuracy        1.515198       0.137114  15.637457                 0.001218                0.001093           0.004335            3       True          3\r\n","2     WeightedEnsemble_L2       0.576923   0.694581    accuracy        1.515894       0.137257  15.638064                 0.001915                0.001236           0.004942            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_cc2a6c0f30a049edb7dbd57748295f79\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.67s of the 3.99s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6856\t = Validation score   (accuracy)\r\n","\t22.58s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.00s of the -22.05s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/11.6 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6856\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.00s of the -22.26s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/11.4 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6856\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 26.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 286.6 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_cc2a6c0f30a049edb7dbd57748295f79\")\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5696\r\n","Ordering Iter 8/10 quick AutoGluon: 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","ACO Iter 1/10 — best: 0.5570 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4177\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","ACO Iter 2/10 — best: 0.5696 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5316\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4430\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 5/10 — best: 0.5823 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'zscore', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4684\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5823\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5063\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5443\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  2. {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  3. {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  4. {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","  5. {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_08be5a5927404d01a2c0bf27c5710023/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.538462   0.674877    accuracy        1.569514       0.082652  16.304029                 1.569514                0.082652          16.304029            1       True          1\r\n","1     WeightedEnsemble_L3       0.538462   0.674877    accuracy        1.570906       0.083929  16.312586                 0.001392                0.001277           0.008558            3       True          3\r\n","2     WeightedEnsemble_L2       0.538462   0.674877    accuracy        1.571478       0.083986  16.309646                 0.001964                0.001334           0.005617            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t28s\t = DyStack   runtime |\t2s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 2s\r\n","AutoGluon will save models to \"/tmp/autogluon_08be5a5927404d01a2c0bf27c5710023\"\r\n","Train Data Rows:    229\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1.31s of the 1.96s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t14.51s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 1.97s of the -15.82s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 1.97s of the -15.95s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6594\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 17.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 327.1 rows/s (29 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_08be5a5927404d01a2c0bf27c5710023\")\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5696\r\n","Ordering Iter 9/10 quick AutoGluon: 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4304\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","ACO Iter 1/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4177\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 2/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.3671\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.3797\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 3/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5570\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","ACO Iter 4/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4684\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","ACO Iter 5/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5190\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 6/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5316\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 7/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5063\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 8/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","ACO Iter 9/10 — best: 0.6076 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.4937\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5443\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5696\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6076\r\n","ACO Iter 10/10 — best: 0.6076 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  2. {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  3. {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  4. {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","  5. {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.6076\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.43 GB / 31.35 GB (87.5%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_365a3d9a0ab6487faecfd6ef0fb583d6/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.666667    0.67757    accuracy        1.419396       0.089903  14.956190                 1.419396                0.089903          14.956190            1       True          1\r\n","1     WeightedEnsemble_L3       0.666667    0.67757    accuracy        1.420913       0.090884  14.959975                 0.001517                0.000981           0.003784            3       True          3\r\n","2     WeightedEnsemble_L2       0.666667    0.67757    accuracy        1.421362       0.090992  14.960823                 0.001966                0.001089           0.004633            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_365a3d9a0ab6487faecfd6ef0fb583d6\"\r\n","Train Data Rows:    241\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3.34s of the 5.00s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6763\t = Validation score   (accuracy)\r\n","\t15.54s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.01s of the -13.65s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6763\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.01s of the -13.76s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/25.9 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.6763\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 18.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 367.0 rows/s (31 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_365a3d9a0ab6487faecfd6ef0fb583d6\")\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6329\r\n","Ordering Iter 10/10 quick AutoGluon: 0.6329\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       25.92 GB / 31.35 GB (82.7%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_b642b05f985243439fea0f82a9d30d78/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0   NeuralNetFastAI_BAG_L1       0.666667   0.677570    accuracy        1.217057       0.073289  16.386092                 1.217057                0.073289          16.386092            1       True          1\r\n","1      WeightedEnsemble_L2       0.666667   0.682243    accuracy        1.300977       0.230804  17.408485                 0.003047                0.000849           0.034768            2       True          6\r\n","2   NeuralNetFastAI_BAG_L2       0.666667   0.742991    accuracy        1.416962       0.373436  44.208208                 0.097687                0.124815          17.092253            2       True          7\r\n","3      WeightedEnsemble_L3       0.666667   0.742991    accuracy        1.418936       0.374306  44.240525                 0.001974                0.000871           0.032317            3       True          9\r\n","4        LightGBMXT_BAG_L2       0.629630   0.742991    accuracy        1.385744       0.291541  37.285681                 0.066469                0.042920          10.169726            2       True          8\r\n","5          LightGBM_BAG_L1       0.592593   0.644860    accuracy        0.021345       0.018666   9.742239                 0.021345                0.018666           9.742239            1       True          3\r\n","6  RandomForestEntr_BAG_L1       0.592593   0.616822    accuracy        0.042535       0.047626   0.536561                 0.042535                0.047626           0.536561            1       True          5\r\n","7  RandomForestGini_BAG_L1       0.592593   0.635514    accuracy        0.080873       0.156666   0.987625                 0.080873                0.156666           0.987625            1       True          4\r\n","8        LightGBMXT_BAG_L1       0.592593   0.612150    accuracy        1.477775       0.012725   9.481553                 1.477775                0.012725           9.481553            1       True          2\r\n","\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\r\n","\t95s\t = DyStack   runtime |\t205s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=0.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\r\n","Beginning AutoGluon training ... Time limit = 205s\r\n","AutoGluon will save models to \"/tmp/autogluon_b642b05f985243439fea0f82a9d30d78\"\r\n","Train Data Rows:    241\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Train Data Class Count: 5\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 204.95s of the 204.94s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6846\t = Validation score   (accuracy)\r\n","\t17.85s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 183.70s of the 183.69s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.29%)\r\n","\t0.6432\t = Validation score   (accuracy)\r\n","\t10.16s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 169.37s of the 169.36s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.29%)\r\n","\t0.6556\t = Validation score   (accuracy)\r\n","\t10.01s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 155.34s of the 155.33s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6349\t = Validation score   (accuracy)\r\n","\t0.75s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 154.45s of the 154.44s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6307\t = Validation score   (accuracy)\r\n","\t0.85s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 153.50s of the 153.49s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.42%)\r\n","\t0.668\t = Validation score   (accuracy)\r\n","\t8.1s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 142.51s of the 142.50s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6307\t = Validation score   (accuracy)\r\n","\t0.99s\t = Training   runtime\r\n","\t0.09s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 141.41s of the 141.40s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.6307\t = Validation score   (accuracy)\r\n","\t0.88s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 140.43s of the 140.42s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\r\n","\t0.6763\t = Validation score   (accuracy)\r\n","\t4.91s\t = Training   runtime\r\n","\t0.03s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 132.63s of the 132.62s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6473\t = Validation score   (accuracy)\r\n","\t19.62s\t = Training   runtime\r\n","\t0.15s\t = Validation runtime\r\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 109.35s of the 109.34s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.21%)\r\n","\t0.6722\t = Validation score   (accuracy)\r\n","\t11.02s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 94.00s of the 93.99s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.47%)\r\n","\t0.6888\t = Validation score   (accuracy)\r\n","\t9.02s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 80.72s of the 80.71s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6639\t = Validation score   (accuracy)\r\n","\t20.36s\t = Training   runtime\r\n","\t0.13s\t = Validation runtime\r\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 57.09s of the 57.08s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.48%)\r\n","\t0.6515\t = Validation score   (accuracy)\r\n","\t12.17s\t = Training   runtime\r\n","\t0.06s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 41.06s of the 41.05s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.6722\t = Validation score   (accuracy)\r\n","\t20.9s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 15.84s of the 15.83s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.48%)\r\n","\t0.6639\t = Validation score   (accuracy)\r\n","\t11.85s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 204.95s of the 0.03s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.5 GB\r\n","\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\r\n","\t0.6888\t = Validation score   (accuracy)\r\n","\t0.06s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 205.0s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2413.2 rows/s (31 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_b642b05f985243439fea0f82a9d30d78\")\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6456\r\n","\r\n","Final recommendation\r\n","  Dataset: 40663\r\n","  Pipeline: {imputation=constant, scaling=maxabs, encoding=onehot, feature_selection=k_best, outlier_removal=none, dimensionality_reduction=none, step_order=['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}\r\n","  Proxy score: 0.6329\r\n","  Final eval (autogluon): 0.6456\r\n","  Optimizer: aco\r\n","  Ordering search: strategy=heuristic orders=10\r\n","  Saved recommendation: /kaggle/working/dataset_40663/recommendation.json\r\n","  Saved ACO history: /kaggle/working/dataset_40663/aco_history.csv\r\n","  Saved ACO plot: /kaggle/working/dataset_40663/aco_progress.png\r\n","  Elapsed seconds: 1161.03\r\n","2026-02-25 04:13:54,524 | INFO | __main__ | Saved recommendation to /kaggle/working/dataset_40663/recommendation.json\r\n","\r\n","Aggregate summary\r\n","  Runs ok/failed: 2/0\r\n","  Avg elapsed seconds: 1158.62\r\n","  Avg proxy score: 0.6988\r\n","  Avg final score: 0.6463\r\n","  Avg autogluon score: 0.6463\r\n","\r\n","Saved multi-run summary: /kaggle/working/recommendations_summary.json\r\n","\u001b[0m"]}],"source":["# Commit 4\n","!python -m scripts.run_recommend \\\n","  --performance-matrix /kaggle/input/acorec/aco/training_performance_matrix_autogluon.csv \\\n","  --metafeatures /kaggle/input/acorec/aco/dataset_feats.csv \\\n","  --pipeline-configs /kaggle/input/acorec/aco/pipeline_configs.json \\\n","  --dataset-source openml \\\n","  --dataset-ids 862, 40663 \\\n","  --use-aco \\\n","  --search-ordering \\\n","  --num-orders 10 \\\n","  --order-strategy heuristic \\\n","  --ordering-quick-time-limit 30 \\\n","  --seed 42 \\\n","  --n-ants 10 \\\n","  --n-iterations 10 \\\n","  --verbose\n"]},{"cell_type":"code","execution_count":null,"id":"dc2a3da7","metadata":{"papermill":{"duration":0.126023,"end_time":"2026-02-25T04:13:59.861847","exception":false,"start_time":"2026-02-25T04:13:59.735824","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":13918325,"datasetId":8381793,"sourceId":13223565,"sourceType":"datasetVersion"},{"databundleVersionId":13946712,"datasetId":8395330,"sourceId":13249749,"sourceType":"datasetVersion"},{"databundleVersionId":13895196,"datasetId":8367218,"sourceId":13202526,"sourceType":"datasetVersion"},{"databundleVersionId":14038593,"datasetId":8453907,"sourceId":13333380,"sourceType":"datasetVersion"},{"databundleVersionId":13923003,"datasetId":8384633,"sourceId":13227831,"sourceType":"datasetVersion"},{"databundleVersionId":13891890,"datasetId":8363742,"sourceId":13199511,"sourceType":"datasetVersion"},{"databundleVersionId":15822721,"datasetId":9452976,"isSourceIdPinned":true,"sourceId":14952341,"sourceType":"datasetVersion"},{"databundleVersionId":15331670,"datasetId":9264728,"sourceId":14505601,"sourceType":"datasetVersion"},{"databundleVersionId":15304774,"datasetId":9249282,"sourceId":14481267,"sourceType":"datasetVersion"},{"databundleVersionId":14087326,"datasetId":8487747,"sourceId":13378082,"sourceType":"datasetVersion"},{"databundleVersionId":1320025,"datasetId":743713,"sourceId":1287930,"sourceType":"datasetVersion"},{"databundleVersionId":15306559,"datasetId":8786333,"isSourceIdPinned":true,"sourceId":14482880,"sourceType":"datasetVersion"}],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":2446.59468,"end_time":"2026-02-25T04:14:00.409946","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-25T03:33:13.815266","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}