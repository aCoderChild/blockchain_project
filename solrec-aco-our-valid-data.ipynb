{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vuhaidang2005/solrec-aco-our-valid-data?scriptVersionId=299922268\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"17b1a01d","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:32:49.235473Z","iopub.status.busy":"2026-02-25T03:32:49.235156Z","iopub.status.idle":"2026-02-25T03:32:49.248381Z","shell.execute_reply":"2026-02-25T03:32:49.247402Z"},"papermill":{"duration":0.01862,"end_time":"2026-02-25T03:32:49.249886","exception":false,"start_time":"2026-02-25T03:32:49.231266","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/acorec\n"]}],"source":["%cd /kaggle/input/acorec\n"]},{"cell_type":"code","execution_count":2,"id":"d5f6b0d4","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:32:49.255158Z","iopub.status.busy":"2026-02-25T03:32:49.254874Z","iopub.status.idle":"2026-02-25T03:35:05.59772Z","shell.execute_reply":"2026-02-25T03:35:05.596533Z"},"papermill":{"duration":136.347337,"end_time":"2026-02-25T03:35:05.599454","exception":false,"start_time":"2026-02-25T03:32:49.252117","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.3)\r\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\r\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.15.3)\r\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.7.2)\r\n","Collecting autogluon (from -r requirements.txt (line 6))\r\n","  Downloading autogluon-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2025.3.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2022.3.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 1)) (2.4.1)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\r\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.2)\r\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\r\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.2)\r\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\r\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.59.0)\r\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\r\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (25.0)\r\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.3.0)\r\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\r\n","Collecting autogluon.core==1.5.0 (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_core-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting autogluon.features==1.5.0 (from autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_features-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Collecting autogluon.tabular==1.5.0 (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_tabular-1.5.0-py3-none-any.whl.metadata (16 kB)\r\n","Collecting autogluon.multimodal==1.5.0 (from autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_multimodal-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting autogluon.timeseries==1.5.0 (from autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_timeseries-1.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting scikit-learn (from -r requirements.txt (line 3))\r\n","  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n","Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.5)\r\n","Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.67.1)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.32.5)\r\n","Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.40.61)\r\n","Collecting autogluon.common==1.5.0 (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading autogluon_common-1.5.0-py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: ray<2.53,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.51.1)\r\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (19.0.1)\r\n","Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.2.7)\r\n","Collecting stevedore<5.5 (from autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\r\n","Requirement already satisfied: torch<2.10,>=2.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.0+cu124)\r\n","Collecting lightning<2.6,>=2.5.1 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: transformers<4.58,>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.53.3)\r\n","Requirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.9.0)\r\n","Collecting fsspec<=2025.3 (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n","Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\r\n","Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\r\n","Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: torchvision<0.25.0,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.0+cu124)\r\n","Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.25.2)\r\n","Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3)\r\n","Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\r\n","Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.3.0)\r\n","Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\r\n","Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n","Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.9.2)\r\n","Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n","Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.1)\r\n","Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.6)\r\n","Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.18.0)\r\n","Requirement already satisfied: pytesseract<0.4,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.3.13)\r\n","Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Requirement already satisfied: pdf2image<1.19,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.0)\r\n","Collecting einx (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\r\n","Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.6.0)\r\n","Requirement already satisfied: huggingface_hub<1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.36.0)\r\n","Requirement already satisfied: xgboost<3.2,>=2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.3)\r\n","Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.8)\r\n","Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.8.5)\r\n","Collecting loguru (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n","Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.8.1)\r\n","Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.8.7)\r\n","Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\r\n","Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\r\n","Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\r\n","Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\r\n","Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n","Collecting fugue>=0.9.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading fugue-0.9.7-py3-none-any.whl.metadata (18 kB)\r\n","Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.11.0)\r\n","Collecting chronos-forecasting<2.4,>=2.2.2 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading chronos_forecasting-2.2.2-py3-none-any.whl.metadata (23 kB)\r\n","Requirement already satisfied: peft<0.18,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.16.0)\r\n","Requirement already satisfied: psutil<7.2.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (7.1.3)\r\n","Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.0.3)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\r\n","Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2025.3.0)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 1)) (2022.3.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 1)) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.5.3)\r\n","Requirement already satisfied: botocore<1.41.0,>=1.40.61 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.40.61)\r\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.1)\r\n","Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.14.0)\r\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21)\r\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (5.24.1)\r\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.4.1)\r\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.0)\r\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.6.0)\r\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.70.18)\r\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (24.1.2)\r\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.0.7)\r\n","Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.8.15)\r\n","Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.0.2)\r\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.3)\r\n","Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.0)\r\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.2)\r\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.13.2)\r\n","Collecting triad>=1.0.1 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading triad-1.0.2-py3-none-any.whl.metadata (6.6 kB)\r\n","Collecting adagio>=0.2.6 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\r\n","Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.12.4)\r\n","Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.15.0)\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.20.0)\r\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.0)\r\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.0)\r\n","Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.10.9.7)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 1)) (2024.2.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.3)\r\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (25.4.0)\r\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.4.1)\r\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.36.2)\r\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.26.0)\r\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.15.2)\r\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.5)\r\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.60.0)\r\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.5.0)\r\n","Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (5.2.0)\r\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (8.3.0)\r\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.11.3)\r\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.9.3)\r\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.6)\r\n","Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n","Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (14.2.0)\r\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.9.0)\r\n","Collecting click (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\r\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.1.2)\r\n","Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.33.0)\r\n","Collecting aiohttp_cors (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\r\n","Collecting colorful (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\r\n","Collecting py-spy>=0.2.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\r\n","Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.74.0)\r\n","Collecting opencensus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\n","Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.60b1-py3-none-any.whl.metadata (2.1 kB)\r\n","Requirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.22.1)\r\n","Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (7.3.0.post1)\r\n","Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading virtualenv-20.39.0-py3-none-any.whl.metadata (3.5 kB)\r\n","Collecting tensorboardX>=1.9 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\r\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.4.4)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.11)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.10.5)\r\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.37.0)\r\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2025.6.11)\r\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4)\r\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.12)\r\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.5)\r\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.13)\r\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.11)\r\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.0.10)\r\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (8.3.6)\r\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.1.3)\r\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.5.1)\r\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.10)\r\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.1)\r\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.16.0)\r\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (75.2.0)\r\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.5.0)\r\n","Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.14.5)\r\n","Collecting pbr>=2.0.0 (from stevedore<5.5->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading pbr-7.0.3-py2.py3-none-any.whl.metadata (3.8 kB)\r\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.4.0)\r\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.8.2)\r\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.2)\r\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.1.3)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.6.2)\r\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.21.5)\r\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (12.4.127)\r\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.2.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.58,>=4.51.0->transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.2)\r\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.2.0)\r\n","Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.4.6)\r\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.6.1)\r\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.4.0)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.8.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (6.7.0)\r\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.1)\r\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.22.0)\r\n","INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\r\n","  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\r\n","  Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\r\n","INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\r\n","  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\r\n","Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n","Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.13.4)\r\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.43.0)\r\n","Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.37.0)\r\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.58b0)\r\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (8.7.0)\r\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.7.0)\r\n","Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.41.5)\r\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.2)\r\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.0.1)\r\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.0)\r\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.1.5)\r\n","INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)\r\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.5.4)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (4.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.19.2)\r\n","Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\r\n","Collecting filelock (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\r\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.5.0)\r\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.21.1)\r\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.2)\r\n","Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n","Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\r\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.28.1)\r\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (3.23.0)\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\r\n","INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.60b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\r\n","Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl.metadata (2.1 kB)\r\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.17.1)\r\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (6.10.1)\r\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.0.41)\r\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (9.1.2)\r\n","Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.11/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.22.5)\r\n","Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.3.10)\r\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.70.0)\r\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.26.1)\r\n","Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (2.38.0)\r\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (1.2.1)\r\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (0.1.2)\r\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.2.3)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (2.7)\r\n","INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n","Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\r\n","  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\r\n","INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n","  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\r\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n","  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\r\n","  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\r\n","  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\r\n","  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\r\n","  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\r\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon->-r requirements.txt (line 6)) (1.7.1)\r\n","Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6))\r\n","  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.4.2)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (4.9.1)\r\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (3.23.0)\r\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon->-r requirements.txt (line 6)) (0.6.1)\r\n","Downloading autogluon-1.5.0-py3-none-any.whl (5.9 kB)\r\n","Downloading autogluon_core-1.5.0-py3-none-any.whl (227 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_features-1.5.0-py3-none-any.whl (98 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_multimodal-1.5.0-py3-none-any.whl (452 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.1/452.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_tabular-1.5.0-py3-none-any.whl (515 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_timeseries-1.5.0-py3-none-any.whl (244 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading autogluon_common-1.5.0-py3-none-any.whl (74 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading chronos_forecasting-2.2.2-py3-none-any.whl (72 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.8/285.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading fugue-0.9.7-py3-none-any.whl (281 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading lightning-2.5.6-py3-none-any.whl (827 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\r\n","Downloading click-8.3.1-py3-none-any.whl (108 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading pbr-7.0.3-py2.py3-none-any.whl (131 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading triad-1.0.2-py3-none-any.whl (59 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading virtualenv-20.39.0-py3-none-any.whl (5.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading filelock-3.24.3-py3-none-any.whl (24 kB)\r\n","Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\r\n","Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n","Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n","Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl (13 kB)\r\n","Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\r\n","Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\r\n","Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n","Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\r\n","Building wheels for collected packages: nvidia-ml-py3, seqeval\r\n","  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=3a0729a1e5f42dc60807839ede488fe21ddf9af46c3db672edb3810a31940b00\r\n","  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\r\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=ad54c1d2bae4cb42a7a2c33aff438e5959379c40f672ffad2da7aaf9ca098a55\r\n","  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\r\n","Successfully built nvidia-ml-py3 seqeval\r\n","Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, toolz, pbr, ordered-set, openxlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, fsspec, filelock, dill, click, cachetools, virtualenv, stevedore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, opendatalab, nvidia-cusolver-cu12, jsonschema, aiohttp_cors, opencensus, opentelemetry-exporter-prometheus, triad, scikit-learn, autogluon.common, torchmetrics, autogluon.features, autogluon.core, adagio, window-ops, utilsforecast, thinc, tensorboardX, fugue, coreforecast, autogluon.tabular, statsforecast, mlforecast, lightning, gluonts, datasets, chronos-forecasting, timm, seqeval, pytorch-metric-learning, openmim, nlpaug, evaluate, einx, autogluon.timeseries, autogluon.multimodal, autogluon\r\n","  Attempting uninstall: toolz\r\n","    Found existing installation: toolz 1.1.0\r\n","    Uninstalling toolz-1.1.0:\r\n","      Successfully uninstalled toolz-1.1.0\r\n","  Attempting uninstall: nvidia-nvjitlink-cu12\r\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-curand-cu12\r\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n","  Attempting uninstall: nvidia-cufft-cu12\r\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cublas-cu12\r\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n","  Attempting uninstall: fsspec\r\n","    Found existing installation: fsspec 2025.10.0\r\n","    Uninstalling fsspec-2025.10.0:\r\n","      Successfully uninstalled fsspec-2025.10.0\r\n","  Attempting uninstall: filelock\r\n","    Found existing installation: filelock 3.20.0\r\n","    Uninstalling filelock-3.20.0:\r\n","      Successfully uninstalled filelock-3.20.0\r\n","  Attempting uninstall: dill\r\n","    Found existing installation: dill 0.4.0\r\n","    Uninstalling dill-0.4.0:\r\n","      Successfully uninstalled dill-0.4.0\r\n","  Attempting uninstall: click\r\n","    Found existing installation: click 8.3.0\r\n","    Uninstalling click-8.3.0:\r\n","      Successfully uninstalled click-8.3.0\r\n","  Attempting uninstall: cachetools\r\n","    Found existing installation: cachetools 6.2.1\r\n","    Uninstalling cachetools-6.2.1:\r\n","      Successfully uninstalled cachetools-6.2.1\r\n","  Attempting uninstall: nvidia-cusparse-cu12\r\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n","  Attempting uninstall: nvidia-cudnn-cu12\r\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n","  Attempting uninstall: multiprocess\r\n","    Found existing installation: multiprocess 0.70.18\r\n","    Uninstalling multiprocess-0.70.18:\r\n","      Successfully uninstalled multiprocess-0.70.18\r\n","  Attempting uninstall: nvidia-cusolver-cu12\r\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n","  Attempting uninstall: jsonschema\r\n","    Found existing installation: jsonschema 4.25.0\r\n","    Uninstalling jsonschema-4.25.0:\r\n","      Successfully uninstalled jsonschema-4.25.0\r\n","  Attempting uninstall: scikit-learn\r\n","    Found existing installation: scikit-learn 1.2.2\r\n","    Uninstalling scikit-learn-1.2.2:\r\n","      Successfully uninstalled scikit-learn-1.2.2\r\n","  Attempting uninstall: torchmetrics\r\n","    Found existing installation: torchmetrics 1.8.2\r\n","    Uninstalling torchmetrics-1.8.2:\r\n","      Successfully uninstalled torchmetrics-1.8.2\r\n","  Attempting uninstall: thinc\r\n","    Found existing installation: thinc 8.3.6\r\n","    Uninstalling thinc-8.3.6:\r\n","      Successfully uninstalled thinc-8.3.6\r\n","  Attempting uninstall: datasets\r\n","    Found existing installation: datasets 4.4.1\r\n","    Uninstalling datasets-4.4.1:\r\n","      Successfully uninstalled datasets-4.4.1\r\n","  Attempting uninstall: timm\r\n","    Found existing installation: timm 1.0.19\r\n","    Uninstalling timm-1.0.19:\r\n","      Successfully uninstalled timm-1.0.19\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n","category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n","preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\r\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n","sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n","bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n","libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n","gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 autogluon-1.5.0 autogluon.common-1.5.0 autogluon.core-1.5.0 autogluon.features-1.5.0 autogluon.multimodal-1.5.0 autogluon.tabular-1.5.0 autogluon.timeseries-1.5.0 cachetools-5.5.2 chronos-forecasting-2.2.2 click-8.3.1 colorful-0.5.8 coreforecast-0.0.16 datasets-4.0.0 dill-0.3.8 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 filelock-3.24.3 fsspec-2025.3.0 fugue-0.9.7 gluonts-0.16.2 jsonschema-4.23.0 lightning-2.5.6 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 opentelemetry-exporter-prometheus-0.58b0 openxlab-0.0.11 ordered-set-4.1.0 pbr-7.0.3 py-spy-0.4.1 pytorch-metric-learning-2.8.1 scikit-learn-1.7.2 seqeval-1.2.2 statsforecast-2.0.1 stevedore-5.4.1 tensorboardX-2.6.4 thinc-8.3.10 timm-1.0.3 toolz-0.12.1 torchmetrics-1.7.4 triad-1.0.2 utilsforecast-0.2.11 virtualenv-20.39.0 window-ops-0.0.15\r\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"id":"6d68abf8","metadata":{"execution":{"iopub.execute_input":"2026-02-25T03:35:05.688384Z","iopub.status.busy":"2026-02-25T03:35:05.688056Z","iopub.status.idle":"2026-02-25T04:17:49.463065Z","shell.execute_reply":"2026-02-25T04:17:49.461451Z"},"papermill":{"duration":2563.822298,"end_time":"2026-02-25T04:17:49.465348","exception":false,"start_time":"2026-02-25T03:35:05.64305","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded performance matrix: /kaggle/input/acorec/aco/training_performance_matrix_autogluon.csv\r\n","Loaded metafeatures: /kaggle/input/acorec/aco/dataset_feats.csv\r\n","Loaded pipeline configs: /kaggle/input/acorec/aco/pipeline_configs.json\r\n","Aligned datasets: 29\r\n","\r\n","=== Dataset 1066 (1/2) ===\r\n","Loaded dataset 1066\r\n","  Shape: (145, 94)\r\n","  Task: classification\r\n","  Target classes: 2\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 3/10 — best: 0.7586 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 6/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 7/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 8/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 9/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","ACO Iter 10/10 — best: 0.8276 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  2. {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  3. {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  4. {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  5. {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       29.55 GB / 31.35 GB (94.3%)\r\n","Disk Space Avail:   1385.25 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\r\n","2026-02-25 03:35:55,732\tINFO worker.py:2003 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\r\n","/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\r\n","  warnings.warn(\r\n","Warning: Not enough time to fit DyStack! Skipping...\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t10s\t = DyStack   runtime |\t20s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 20s\r\n","AutoGluon will save models to \"/tmp/autogluon_fec847b95d524773815e48555b6acd94\"\r\n","Train Data Rows:    82\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 13.10s of the 19.64s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t15.56s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 19.65s of the 1.06s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.7 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1.05s of the 1.02s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t11.37s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 19.65s of the -14.84s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.7 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 34.52s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1292.4 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (82 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_fec847b95d524773815e48555b6acd94\")\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","Ordering Iter 1/10 quick AutoGluon: 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","ACO Iter 1/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6207\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 3/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","ACO Iter 4/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 5/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6552\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 6/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 7/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  2. {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  3. {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  4. {'imputation': 'constant', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  5. {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.68 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_a8a83a5afba34394a6fda6f29afc360a/ds_sub_fit/sub_fit_ho\"\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Running DyStack sub-fit ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Beginning AutoGluon training ... Time limit = 7s\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m AutoGluon will save models to \"/tmp/autogluon_a8a83a5afba34394a6fda6f29afc360a/ds_sub_fit/sub_fit_ho\"\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Train Data Rows:    77\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Train Data Columns: 84\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Label Column:       target\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Problem Type:       binary\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Preprocessing data ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Using Feature Generators to preprocess the data ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting IdentityFeatureGenerator...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Data preprocessing and feature engineering runtime = 0.02s ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m User-specified model hyperparameters to be fit:\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m {\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m }\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4.65s of the 6.96s of remaining time.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.8182\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t12.25s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.02s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 6.98s of the -12.10s of remaining time.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.5 GB\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.8182\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.0s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.0s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 6.98s of the -12.18s of remaining time.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.5 GB\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.8182\t = Validation score   (accuracy)\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.0s\t = Training   runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t0.0s\t = Validation runtime\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m AutoGluon training complete, total runtime = 19.19s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 480.7 rows/s (10 batch size)\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (77 rows).\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m \t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_a8a83a5afba34394a6fda6f29afc360a/ds_sub_fit/sub_fit_ho\")\r\n","\u001b[36m(_dystack pid=1327)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.187778       0.020651  12.245521                 2.187778                0.020651          12.245521            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.189222       0.022162  12.249610                 0.001444                0.001511           0.004089            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.189573       0.021832  12.249509                 0.001795                0.001181           0.003989            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t27s\t = DyStack   runtime |\t3s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 3s\r\n","AutoGluon will save models to \"/tmp/autogluon_a8a83a5afba34394a6fda6f29afc360a\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 84\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.02s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2.26s of the 3.38s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t12.03s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 3.40s of the -12.59s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 3.40s of the -12.67s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 714.3 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_a8a83a5afba34394a6fda6f29afc360a\")\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","Ordering Iter 2/10 quick AutoGluon: 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 2/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 3/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 6/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 7/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","ACO Iter 8/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","ACO Iter 9/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","ACO Iter 10/10 — best: 0.8276 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  2. {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  3. {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  4. {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  5. {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_963dde213dad47378ba29c9a0a428d5d/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.8   0.791667    accuracy        2.185119       0.009195  11.933714                 2.185119                0.009195          11.933714            1       True          1\r\n","1  WeightedEnsemble_L3            0.8   0.791667    accuracy        2.186694       0.010864  11.940272                 0.001575                0.001669           0.006557            3       True          3\r\n","2  WeightedEnsemble_L2            0.8   0.791667    accuracy        2.187069       0.011081  11.939883                 0.001951                0.001886           0.006169            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_963dde213dad47378ba29c9a0a428d5d\"\r\n","Train Data Rows:    82\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.57s of the 5.34s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t12.01s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.35s of the -10.51s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.35s of the -10.62s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8293\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.0s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1137.2 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (82 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_963dde213dad47378ba29c9a0a428d5d\")\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","Ordering Iter 3/10 quick AutoGluon: 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.7586 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 2/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6552\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 3/10 — best: 0.7586 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6207\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","ACO Iter 4/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6207\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 5/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","ACO Iter 6/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 7/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  2. {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  3. {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  4. {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8276\r\n","  5. {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.7931\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.68 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_51a5c0a05c25476cbbf8bf1adb4d6b60/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.225804       0.026248  12.143916                 2.225804                0.026248          12.143916            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.227249       0.028161  12.150517                 0.001446                0.001913           0.006601            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.227556       0.027991  12.149819                 0.001753                0.001743           0.005903            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_51a5c0a05c25476cbbf8bf1adb4d6b60\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 84\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.02s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.38s of the 5.06s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t12.45s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.07s of the -11.30s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.07s of the -11.42s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 555.9 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_51a5c0a05c25476cbbf8bf1adb4d6b60\")\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","Ordering Iter 4/10 quick AutoGluon: 0.7241\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 1/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 2/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 3/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 6/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 7/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  2. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  3. {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  4. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","  5. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.68 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_e27f5f92c29e4184a657980a898dcf21/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.230088       0.020270  11.821072                 2.230088                0.020270          11.821072            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.231644       0.022199  11.832502                 0.001556                0.001929           0.011430            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.232072       0.025345  11.833501                 0.001984                0.005075           0.012429            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_e27f5f92c29e4184a657980a898dcf21\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 94\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.03s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.50s of the 5.24s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t11.86s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.25s of the -10.66s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.25s of the -10.80s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 548.4 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_e27f5f92c29e4184a657980a898dcf21\")\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","Ordering Iter 5/10 quick AutoGluon: 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.7586 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","ACO Iter 3/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","ACO Iter 5/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 6/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 7/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  2. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  3. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  4. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  5. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.67 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_03cff7b7e8cd49458896c304f486f831/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.200446       0.022233  11.837034                 2.200446                0.022233          11.837034            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.201895       0.024238  11.843248                 0.001449                0.002006           0.006214            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.202260       0.023392  11.840907                 0.001814                0.001160           0.003873            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_03cff7b7e8cd49458896c304f486f831\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 94\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.03s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.50s of the 5.24s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t11.94s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.26s of the -10.69s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.26s of the -10.80s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.02s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.12s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 568.7 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_03cff7b7e8cd49458896c304f486f831\")\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","Ordering Iter 6/10 quick AutoGluon: 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by StandardScaler.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MinMaxScaler.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MinMaxScaler.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MaxAbsScaler.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 3/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by StandardScaler.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MinMaxScaler.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","ACO Iter 6/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by RobustScaler.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MinMaxScaler.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 7/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MaxAbsScaler.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  2. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  4. {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  5. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.68 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_a551c8d3ba984de880a9397d38fb817d/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.214415       0.018513  11.726871                 2.214415                0.018513          11.726871            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.215967       0.019715  11.730865                 0.001552                0.001202           0.003993            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.216223       0.020157  11.731025                 0.001809                0.001644           0.004154            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t25s\t = DyStack   runtime |\t5s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 5s\r\n","AutoGluon will save models to \"/tmp/autogluon_a551c8d3ba984de880a9397d38fb817d\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 94\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.02s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3.55s of the 5.31s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t11.9s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.33s of the -10.64s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 5.33s of the -10.77s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.8 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 530.8 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_a551c8d3ba984de880a9397d38fb817d\")\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","Ordering Iter 7/10 quick AutoGluon: 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","ACO Iter 1/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","ACO Iter 2/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 3/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.5862\r\n","ACO Iter 4/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6552\r\n","ACO Iter 6/10 — best: 0.8276 | k=2\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 7/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.6897\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 8/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 9/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 10/10 — best: 0.8276 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8276\r\n","  2. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8276\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8276\r\n","  4. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8276\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.68 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_19181be4d65040cea3e482c5424881a4/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.666667    accuracy        2.235049       0.004755  8.161469                 2.235049                0.004755           8.161469            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.666667    accuracy        2.236901       0.005915  8.165566                 0.001852                0.001160           0.004097            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.666667    accuracy        2.237854       0.005996  8.165445                 0.002805                0.001240           0.003977            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t20s\t = DyStack   runtime |\t10s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 10s\r\n","AutoGluon will save models to \"/tmp/autogluon_19181be4d65040cea3e482c5424881a4\"\r\n","Train Data Rows:    44\r\n","Train Data Columns: 10\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6.35s of the 9.51s of remaining time.\r\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\r\n","\t0.6591\t = Validation score   (accuracy)\r\n","\t8.39s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 9.53s of the -2.87s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6591\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 9.53s of the -2.98s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.5 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.6591\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 12.52s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1888.1 rows/s (9 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (44 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_19181be4d65040cea3e482c5424881a4\")\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7241\r\n","Ordering Iter 8/10 quick AutoGluon: 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 1/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MaxAbsScaler.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'zscore', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by StandardScaler.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 3/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by StandardScaler.\r\n","ACO Iter 4/10 — best: 0.7931 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6207\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","ACO Iter 5/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","ACO Iter 6/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","ACO Iter 7/10 — best: 0.8276 | k=2\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6207\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8276\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.6897\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.5862\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7931\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  2. {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  3. {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  4. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8621\r\n","  5. {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.8276\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.67 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_f36973cd65864ab29b3e88c79e05afc8/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.668904       0.087162  22.272179                 2.668904                0.087162          22.272179            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.670771       0.089120  22.296191                 0.001867                0.001958           0.024012            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.671213       0.089091  22.282609                 0.002309                0.001930           0.010430            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t38s\t = DyStack   runtime |\t-8s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -8.35s\r\n","No candidate produced valid evaluation results\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by MaxAbsScaler.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","ACO Iter 1/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6552\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by StandardScaler.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} produced empty TRAIN data\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 2/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 3/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by RobustScaler.\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6207\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 4/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","ACO Iter 5/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 6/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by RobustScaler.\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by VarianceThreshold.\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8276\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.5862\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","ACO Iter 7/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","ACO Iter 8/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:197: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\r\n","  z = np.abs(zscore(X_num))\r\n","/kaggle/input/acorec/src/automl_aco/preprocessing/preprocessor.py:198: RuntimeWarning: invalid value encountered in less\r\n","  mask = pd.Series((z < 3).all(axis=1), index=X_num.index)\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Found array with 0 sample(s) (shape=(0, 94)) while a minimum of 1 is required by SelectKBest.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7931\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7586\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","ACO Iter 9/10 — best: 0.8621 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.6897\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8621\r\n","ACO Iter 10/10 — best: 0.8621 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  2. {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  3. {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  4. {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","  5. {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.8621\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.69 GB / 31.35 GB (88.3%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_49beaf4f9a1f490db62aa7f50629cc03/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0    LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.185664       0.021749  12.418867                 2.185664                0.021749          12.418867            1       True          1\r\n","1  WeightedEnsemble_L3            0.6   0.818182    accuracy        2.187464       0.023385  12.424364                 0.001800                0.001635           0.005497            3       True          3\r\n","2  WeightedEnsemble_L2            0.6   0.818182    accuracy        2.187829       0.022905  12.422871                 0.002165                0.001155           0.004004            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_49beaf4f9a1f490db62aa7f50629cc03\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 84\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.02s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2.66s of the 3.98s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t12.16s\t = Training   runtime\r\n","\t0.01s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.00s of the -12.09s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.00s of the -12.22s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.9 GB\r\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 16.25s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 889.2 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_49beaf4f9a1f490db62aa7f50629cc03\")\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7241\r\n","Ordering Iter 10/10 quick AutoGluon: 0.7241\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.70 GB / 31.35 GB (88.4%)\r\n","Disk Space Avail:   1385.22 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_4b82c628fe2b45899226af815e30a546/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  RandomForestGini_BAG_L1            0.8   0.779221    accuracy        0.080784       0.117894   1.008147                 0.080784                0.117894           1.008147            1       True          3\r\n","1  RandomForestEntr_BAG_L1            0.7   0.779221    accuracy        0.068372       0.102005   0.783936                 0.068372                0.102005           0.783936            1       True          4\r\n","2          CatBoost_BAG_L1            0.7   0.831169    accuracy        0.434885       0.086577  12.247947                 0.434885                0.086577          12.247947            1       True          5\r\n","3      WeightedEnsemble_L2            0.7   0.831169    accuracy        0.437183       0.087735  12.291845                 0.002299                0.001159           0.043898            2       True          6\r\n","4          LightGBM_BAG_L1            0.6   0.818182    accuracy        0.014680       0.035858  12.223515                 0.014680                0.035858          12.223515            1       True          2\r\n","5        LightGBMXT_BAG_L1            0.6   0.818182    accuracy        2.147817       0.023429  11.984814                 2.147817                0.023429          11.984814            1       True          1\r\n","6        LightGBMXT_BAG_L2            0.6   0.870130    accuracy        2.679885       0.282622  37.349518                 0.016399                0.054722          12.108610            2       True          7\r\n","7          LightGBM_BAG_L2            0.6   0.831169    accuracy        2.680463       0.293046  37.512135                 0.016977                0.065146          12.271227            2       True          8\r\n","8      WeightedEnsemble_L3            0.6   0.870130    accuracy        2.681508       0.285398  37.424619                 0.001623                0.002776           0.075101            3       True          9\r\n","\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\r\n","\t94s\t = DyStack   runtime |\t206s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=0.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\r\n","Beginning AutoGluon training ... Time limit = 206s\r\n","AutoGluon will save models to \"/tmp/autogluon_4b82c628fe2b45899226af815e30a546\"\r\n","Train Data Rows:    87\r\n","Train Data Columns: 94\r\n","Label Column:       target\r\n","Problem Type:       binary\r\n","Preprocessing data ...\r\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.02s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 205.89s of the 205.88s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\r\n","\t0.8276\t = Validation score   (accuracy)\r\n","\t12.31s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 189.60s of the 189.59s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\r\n","\t0.7931\t = Validation score   (accuracy)\r\n","\t12.23s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 172.48s of the 172.47s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.7816\t = Validation score   (accuracy)\r\n","\t1.19s\t = Training   runtime\r\n","\t0.16s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 171.10s of the 171.09s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.7471\t = Validation score   (accuracy)\r\n","\t0.82s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 170.15s of the 170.14s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.64%)\r\n","\t0.8161\t = Validation score   (accuracy)\r\n","\t13.04s\t = Training   runtime\r\n","\t0.07s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 153.20s of the 153.19s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.7586\t = Validation score   (accuracy)\r\n","\t0.86s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 152.20s of the 152.19s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.7586\t = Validation score   (accuracy)\r\n","\t0.79s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 151.29s of the 151.28s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.8621\t = Validation score   (accuracy)\r\n","\t21.09s\t = Training   runtime\r\n","\t0.12s\t = Validation runtime\r\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 126.36s of the 126.35s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.16%)\r\n","\t0.7701\t = Validation score   (accuracy)\r\n","\t5.72s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 115.83s of the 115.82s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.7931\t = Validation score   (accuracy)\r\n","\t26.8s\t = Training   runtime\r\n","\t0.66s\t = Validation runtime\r\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 84.47s of the 84.46s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.49%)\r\n","\t0.7471\t = Validation score   (accuracy)\r\n","\t12.74s\t = Training   runtime\r\n","\t0.03s\t = Validation runtime\r\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 66.07s of the 66.06s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.70%)\r\n","\t0.8391\t = Validation score   (accuracy)\r\n","\t14.09s\t = Training   runtime\r\n","\t0.08s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 47.09s of the 47.07s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t21.28s\t = Training   runtime\r\n","\t0.67s\t = Validation runtime\r\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 20.47s of the 20.46s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.20%)\r\n","\t0.7816\t = Validation score   (accuracy)\r\n","\t12.93s\t = Training   runtime\r\n","\t0.02s\t = Validation runtime\r\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2.39s of the 2.38s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.8046\t = Validation score   (accuracy)\r\n","\t19.25s\t = Training   runtime\r\n","\t0.16s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 205.89s of the -21.69s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.3 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.8621\t = Validation score   (accuracy)\r\n","\t0.14s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 227.76s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 90.6 rows/s (11 batch size)\r\n","Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (87 rows).\r\n","\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_4b82c628fe2b45899226af815e30a546\")\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7241\r\n","\r\n","Final recommendation\r\n","  Dataset: 1066\r\n","  Pipeline: {imputation=none, scaling=none, encoding=onehot, feature_selection=none, outlier_removal=none, dimensionality_reduction=none, step_order=['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}\r\n","  Proxy score: 0.8621\r\n","  Final eval (autogluon): 0.7241\r\n","  Optimizer: aco\r\n","  Ordering search: strategy=heuristic orders=10\r\n","  Saved recommendation: /kaggle/working/dataset_1066/recommendation.json\r\n","  Saved ACO history: /kaggle/working/dataset_1066/aco_history.csv\r\n","  Saved ACO plot: /kaggle/working/dataset_1066/aco_progress.png\r\n","  Elapsed seconds: 1205.89\r\n","2026-02-25 03:55:17,342 | INFO | __main__ | Saved recommendation to /kaggle/working/dataset_1066/recommendation.json\r\n","\r\n","=== Dataset 1047 (2/2) ===\r\n","Loaded dataset 1047\r\n","  Shape: (191, 16)\r\n","  Task: classification\r\n","  Target classes: 4\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  2. {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  3. {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  4. {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  5. {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.54 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_448f663e218d4242b6f1caade34f8b3f/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1            1.0   0.901961    accuracy        1.167064       0.109292  18.847711                 1.167064                0.109292          18.847711            1       True          1\r\n","1     WeightedEnsemble_L3            1.0   0.901961    accuracy        1.168685       0.110348  18.851721                 0.001621                0.001056           0.004009            3       True          3\r\n","2     WeightedEnsemble_L2            1.0   0.901961    accuracy        1.168938       0.110422  18.851951                 0.001874                0.001130           0.004240            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t31s\t = DyStack   runtime |\t-1s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -0.91s\r\n","No candidate produced valid evaluation results\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 1.0000 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","ACO Iter 3/10 — best: 0.9211 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","ACO Iter 4/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 5/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","ACO Iter 6/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","ACO Iter 7/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'none', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'robust', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 8/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","ACO Iter 9/10 — best: 1.0000 | k=2\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 1.0000\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","ACO Iter 10/10 — best: 1.0000 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 1.0000\r\n","  2. {'imputation': 'knn', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 1.0000\r\n","  3. {'imputation': 'mean', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 1.0000\r\n","  4. {'imputation': 'median', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 1.0000\r\n","  5. {'imputation': 'constant', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 1.0000\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       8.48 GB / 31.35 GB (27.0%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_d0d0812841dd40d686e60b3de570efb7/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.615385   0.907216    accuracy        1.368719       0.108043  18.839584                 1.368719                0.108043          18.839584            1       True          1\r\n","1     WeightedEnsemble_L3       0.615385   0.907216    accuracy        1.371176       0.112766  18.850993                 0.002457                0.004723           0.011409            3       True          3\r\n","2     WeightedEnsemble_L2       0.615385   0.907216    accuracy        1.371328       0.109814  18.851871                 0.002609                0.001771           0.012286            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t33s\t = DyStack   runtime |\t-3s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -3.49s\r\n","No candidate produced valid evaluation results\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 1/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'none', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 3/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 4/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 5/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","ACO Iter 6/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'robust', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 7/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","ACO Iter 8/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9737 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","    ✓ {'imputation': 'knn', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} -> 0.9737\r\n","ACO Iter 10/10 — best: 0.9737 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.9737\r\n","  2. {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.9737\r\n","  3. {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.9737\r\n","  4. {'imputation': 'mean', 'scaling': 'robust', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.9737\r\n","  5. {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']} — score: 0.9737\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.53 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_53516b7f7b7247818e304cdadd89830e/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1       0.923077   0.891089    accuracy        1.353968       0.144444  18.752193                 1.353968                0.144444          18.752193            1       True          1\r\n","1     WeightedEnsemble_L3       0.923077   0.891089    accuracy        1.355550       0.145650  18.756277                 0.001581                0.001206           0.004084            3       True          3\r\n","2     WeightedEnsemble_L2       0.923077   0.891089    accuracy        1.355919       0.146015  18.758410                 0.001951                0.001571           0.006217            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t31s\t = DyStack   runtime |\t-1s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'feature_selection', 'dimensionality_reduction']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -1.44s\r\n","No candidate produced valid evaluation results\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'robust', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'scaling': 'standard', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  2. {'imputation': 'mean', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  3. {'imputation': 'constant', 'scaling': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  4. {'imputation': 'most_frequent', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  5. {'imputation': 'constant', 'scaling': 'minmax', 'outlier_removal': 'lof', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.51 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_1b63f51c512942aa99749638a7ab9035/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t17s\t = DyStack   runtime |\t13s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 13s\r\n","AutoGluon will save models to \"/tmp/autogluon_1b63f51c512942aa99749638a7ab9035\"\r\n","Train Data Rows:    115\r\n","Train Data Columns: 297\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.06s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.92s of the 13.38s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t21.05s\t = Training   runtime\r\n","\t0.16s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 13.39s of the -11.54s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 13.39s of the -11.69s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 25.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 93.2 rows/s (15 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_1b63f51c512942aa99749638a7ab9035\")\r\n","    ✓ {'imputation': 'constant', 'scaling': 'standard', 'outlier_removal': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'scaling', 'outlier_removal', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","Ordering Iter 4/10 quick AutoGluon: 0.8947\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  2. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  3. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  4. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  5. {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.54 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_6044a22cc6df437ca6aa83256260cf14/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1            1.0   0.916667    accuracy        1.250029       0.095029  18.764423                 1.250029                0.095029          18.764423            1       True          1\r\n","1     WeightedEnsemble_L3            1.0   0.916667    accuracy        1.252250       0.097788  18.776379                 0.002222                0.002759           0.011956            3       True          3\r\n","2     WeightedEnsemble_L2            1.0   0.916667    accuracy        1.252410       0.096735  18.769830                 0.002382                0.001706           0.005407            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t31s\t = DyStack   runtime |\t-1s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'feature_selection', 'dimensionality_reduction']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -1.31s\r\n","No candidate produced valid evaluation results\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 1/10 — best: 0.9211 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","ACO Iter 2/10 — best: 0.9211 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'dimensionality_reduction': 'svd', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'lof', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7632\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'maxabs', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'isolation_forest', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'iqr', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'scaling': 'robust', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  2. {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'standard', 'outlier_removal': 'zscore', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'scaling': 'minmax', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  4. {'imputation': 'knn', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  5. {'imputation': 'median', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.52 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_a5a0ccbe3de74c54b84b2540024d601b/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t17s\t = DyStack   runtime |\t13s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 13s\r\n","AutoGluon will save models to \"/tmp/autogluon_a5a0ccbe3de74c54b84b2540024d601b\"\r\n","Train Data Rows:    115\r\n","Train Data Columns: 297\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.06s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.62s of the 12.92s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t21.47s\t = Training   runtime\r\n","\t0.16s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 12.93s of the -12.19s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 12.93s of the -12.35s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 25.36s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 92.7 rows/s (15 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_a5a0ccbe3de74c54b84b2540024d601b\")\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'scaling': 'none', 'outlier_removal': 'none', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'encoding', 'scaling', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","Ordering Iter 6/10 quick AutoGluon: 0.8947\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7632\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 3/10 — best: 0.8684 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  2. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  3. {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  4. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  5. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.53 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_14310ce7114f48f69163857b89675fed/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t16s\t = DyStack   runtime |\t14s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 14s\r\n","AutoGluon will save models to \"/tmp/autogluon_14310ce7114f48f69163857b89675fed\"\r\n","Train Data Rows:    114\r\n","Train Data Columns: 297\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.07s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.97s of the 13.45s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\r\n","\t0.9474\t = Validation score   (accuracy)\r\n","\t21.08s\t = Training   runtime\r\n","\t0.15s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 13.47s of the -11.53s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9474\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 13.47s of the -11.71s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9474\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 25.26s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 101.4 rows/s (15 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_14310ce7114f48f69163857b89675fed\")\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","Ordering Iter 7/10 quick AutoGluon: 0.8684\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8158\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8158\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'mutual_info', 'scaling': 'robust', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'mutual_info', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'none', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8947\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'k_best', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'minmax', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'mutual_info', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'k_best', 'scaling': 'minmax', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']}: at least one array or dtype is required\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'robust', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'zscore', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'iqr', 'feature_selection': 'variance_threshold', 'scaling': 'maxabs', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'encoding': 'onehot', 'outlier_removal': 'lof', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.9474\r\n","  2. {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.9474\r\n","  3. {'imputation': 'mean', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.9474\r\n","  4. {'imputation': 'most_frequent', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.9474\r\n","  5. {'imputation': 'constant', 'encoding': 'onehot', 'outlier_removal': 'none', 'feature_selection': 'none', 'scaling': 'standard', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       25.00 GB / 31.35 GB (79.7%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_764f59d589704df2ac9c5b19cdf5c91e/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t26s\t = DyStack   runtime |\t4s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 4s\r\n","AutoGluon will save models to \"/tmp/autogluon_764f59d589704df2ac9c5b19cdf5c91e\"\r\n","Train Data Rows:    109\r\n","Train Data Columns: 141\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 4 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.04s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2.89s of the 4.33s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.9725\t = Validation score   (accuracy)\r\n","\t20.19s\t = Training   runtime\r\n","\t0.23s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 4.34s of the -19.55s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9725\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 4.34s of the -19.68s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9725\t = Validation score   (accuracy)\r\n","\t0.0s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 24.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 61.9 rows/s (14 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_764f59d589704df2ac9c5b19cdf5c91e\")\r\n","    ✓ {'imputation': 'median', 'encoding': 'onehot', 'outlier_removal': 'isolation_forest', 'feature_selection': 'variance_threshold', 'scaling': 'standard', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'encoding', 'outlier_removal', 'feature_selection', 'scaling', 'dimensionality_reduction']} -> 0.8421\r\n","Ordering Iter 8/10 quick AutoGluon: 0.8421\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✗ Error evaluating cfg {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 1/10 — best: 0.9474 | k=2\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'lof', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","ACO Iter 2/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✗ Error evaluating cfg {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 4/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'svd', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'iqr', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.7895\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8158\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'mean', 'outlier_removal': 'isolation_forest', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'robust', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']}: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'minmax', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'k_best', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'variance_threshold', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'scaling': 'maxabs', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.9474\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  2. {'imputation': 'none', 'outlier_removal': 'none', 'scaling': 'none', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  3. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'none', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  4. {'imputation': 'mean', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","  5. {'imputation': 'none', 'outlier_removal': 'zscore', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.55 GB / 31.35 GB (87.9%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_466fda5ba7824bddb58413ab22786047/ds_sub_fit/sub_fit_ho\"\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t17s\t = DyStack   runtime |\t13s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","Beginning AutoGluon training ... Time limit = 13s\r\n","AutoGluon will save models to \"/tmp/autogluon_466fda5ba7824bddb58413ab22786047\"\r\n","Train Data Rows:    115\r\n","Train Data Columns: 297\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.07s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.59s of the 12.88s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.01%)\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t21.23s\t = Training   runtime\r\n","\t0.13s\t = Validation runtime\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 12.89s of the -12.21s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 12.89s of the -12.37s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/26.0 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9304\t = Validation score   (accuracy)\r\n","\t0.01s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 25.35s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 111.0 rows/s (15 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_466fda5ba7824bddb58413ab22786047\")\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'scaling': 'standard', 'encoding': 'onehot', 'dimensionality_reduction': 'pca', 'feature_selection': 'none', 'step_order': ['imputation', 'outlier_removal', 'scaling', 'encoding', 'dimensionality_reduction', 'feature_selection']} -> 0.8947\r\n","Ordering Iter 9/10 quick AutoGluon: 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","ACO Iter 1/10 — best: 0.9211 | k=2\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7105\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","ACO Iter 2/10 — best: 0.9211 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7632\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'k_best', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7368\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 3/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","ACO Iter 4/10 — best: 0.9211 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 5/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 6/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'knn', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'lof', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8421\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 7/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'none', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'iqr', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.7895\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'median', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 8/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'zscore', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'robust', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'k_best', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8947\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'isolation_forest', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'maxabs', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'minmax', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","ACO Iter 9/10 — best: 0.9474 | k=2\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'mutual_info', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.8684\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9211\r\n","    ✓ {'imputation': 'mean', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","    ✓ {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} -> 0.9474\r\n","ACO Iter 10/10 — best: 0.9474 | k=2\r\n","\r\n","🏆 Top pipelines (k-order Markov ACO):\r\n","  1. {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  2. {'imputation': 'none', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  3. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  4. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'none', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","  5. {'imputation': 'most_frequent', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'none', 'dimensionality_reduction': 'svd', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']} — score: 0.9474\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.53 GB / 31.35 GB (87.8%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 7s of the 30s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_dff317a1650e468292257fabaf42b694/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  NeuralNetFastAI_BAG_L1            1.0   0.901961    accuracy        1.235473       0.112316  18.928858                 1.235473                0.112316          18.928858            1       True          1\r\n","1     WeightedEnsemble_L3            1.0   0.901961    accuracy        1.237045       0.114137  18.935357                 0.001572                0.001821           0.006499            3       True          3\r\n","2     WeightedEnsemble_L2            1.0   0.901961    accuracy        1.237525       0.113971  18.935083                 0.002052                0.001655           0.006225            2       True          2\r\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\r\n","\t31s\t = DyStack   runtime |\t-1s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=1.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\r\n","    ✗ Error evaluating cfg {'imputation': 'constant', 'outlier_removal': 'none', 'encoding': 'onehot', 'scaling': 'standard', 'feature_selection': 'variance_threshold', 'dimensionality_reduction': 'pca', 'step_order': ['imputation', 'outlier_removal', 'encoding', 'scaling', 'feature_selection', 'dimensionality_reduction']}: Not enough time left to train models for the full fit. Consider specifying a larger time_limit or setting `dynamic_stacking=False`. Time remaining: -1.26s\r\n","No candidate produced valid evaluation results\r\n","Verbosity: 2 (Standard Logging)\r\n","=================== System Info ===================\r\n","AutoGluon Version:  1.5.0\r\n","Python Version:     3.11.13\r\n","Operating System:   Linux\r\n","Platform Machine:   x86_64\r\n","Platform Version:   #1 SMP Sat Jan 17 11:20:45 UTC 2026\r\n","CPU Count:          4\r\n","Pytorch Version:    2.6.0+cu124\r\n","CUDA Version:       CUDA is not available\r\n","Memory Avail:       27.56 GB / 31.35 GB (87.9%)\r\n","Disk Space Avail:   1385.18 GB / 8062.39 GB (17.2%)\r\n","===================================================\r\n","Presets specified: ['best_quality']\r\n","Using hyperparameters preset: hyperparameters='zeroshot'\r\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\r\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\r\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\r\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\r\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\r\n","\t\tContext path: \"/tmp/autogluon_642170d3e5fe4314885cfdd051befec4/ds_sub_fit/sub_fit_ho\"\r\n","Leaderboard on holdout data (DyStack):\r\n","                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\r\n","0  RandomForestEntr_BAG_L1       0.846154   0.938144    accuracy        0.081254       0.106157   0.820195                 0.081254                0.106157           0.820195            1       True          3\r\n","1          CatBoost_BAG_L1       0.846154   0.917526    accuracy        0.155134       0.045597   9.620746                 0.155134                0.045597           9.620746            1       True          4\r\n","2  RandomForestGini_BAG_L1       0.769231   0.938144    accuracy        0.088594       0.102833   1.029580                 0.088594                0.102833           1.029580            1       True          2\r\n","3      WeightedEnsemble_L2       0.769231   0.938144    accuracy        0.090883       0.104376   1.097340                 0.002289                0.001543           0.067760            2       True          5\r\n","4   NeuralNetFastAI_BAG_L2       0.692308   0.958763    accuracy        1.614996       0.392796  48.882151                 0.114351                0.143739          19.208604            2       True          6\r\n","5      WeightedEnsemble_L3       0.692308   0.958763    accuracy        1.616928       0.394308  48.933888                 0.001933                0.001512           0.051737            3       True          7\r\n","6   NeuralNetFastAI_BAG_L1       0.615385   0.907216    accuracy        1.256916       0.100626  19.023222                 1.256916                0.100626          19.023222            1       True          1\r\n","\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\r\n","\t87s\t = DyStack   runtime |\t213s\t = Remaining runtime\r\n","Starting main fit with num_stack_levels=0.\r\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\r\n","Beginning AutoGluon training ... Time limit = 213s\r\n","AutoGluon will save models to \"/tmp/autogluon_642170d3e5fe4314885cfdd051befec4\"\r\n","Train Data Rows:    110\r\n","Train Data Columns: 20\r\n","Label Column:       target\r\n","Problem Type:       multiclass\r\n","Preprocessing data ...\r\n","Warning: Updated label_count_threshold from 10 to 4 to avoid cutting too many classes.\r\n","Train Data Class Count: 4\r\n","Using Feature Generators to preprocess the data ...\r\n","Fitting IdentityFeatureGenerator...\r\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\r\n","Data preprocessing and feature engineering runtime = 0.01s ...\r\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\r\n","\tTo change this, specify the eval_metric parameter of Predictor()\r\n","Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\r\n","User-specified model hyperparameters to be fit:\r\n","{\r\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\r\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\r\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\r\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\r\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\r\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\r\n","}\r\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\r\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 212.61s of the 212.60s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.9455\t = Validation score   (accuracy)\r\n","\t20.02s\t = Training   runtime\r\n","\t0.12s\t = Validation runtime\r\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 188.44s of the 188.43s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.24%)\r\n","\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\r\n","\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20220, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'DBMS_MySQL', 'DBMS_SQLServer',\\n       'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Detailed Traceback:\r\n","Traceback (most recent call last):\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\r\n","    model = self._train_single(**model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\r\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\r\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\r\n","    self._fit_folds(\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\r\n","    fold_fitting_strategy.after_all_folds_scheduled()\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\r\n","    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\r\n","    self._process_fold_results(finished, unfinished, fold_ctx)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\r\n","    raise processed_exception\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\r\n","    out = self.ray.get(finished)\r\n","          ^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\r\n","    return fn(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\r\n","    return func(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2961, in get\r\n","    values, debugger_breakpoint = worker.get_objects(\r\n","                                  ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 1026, in get_objects\r\n","    raise value.as_instanceof_cause()\r\n","ray.exceptions.RayTaskError(KeyError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20220, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'DBMS_MySQL', 'DBMS_SQLServer',\\n       'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 179.44s of the 179.43s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.22%)\r\n","\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\r\n","\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20403, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Detailed Traceback:\r\n","Traceback (most recent call last):\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\r\n","    model = self._train_single(**model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\r\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\r\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\r\n","    self._fit_folds(\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\r\n","    fold_fitting_strategy.after_all_folds_scheduled()\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\r\n","    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\r\n","    self._process_fold_results(finished, unfinished, fold_ctx)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\r\n","    raise processed_exception\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\r\n","    out = self.ray.get(finished)\r\n","          ^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\r\n","    return fn(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\r\n","    return func(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2961, in get\r\n","    values, debugger_breakpoint = worker.get_objects(\r\n","                                  ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 1026, in get_objects\r\n","    raise value.as_instanceof_cause()\r\n","ray.exceptions.RayTaskError(KeyError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20403, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 171.77s of the 171.76s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.9364\t = Validation score   (accuracy)\r\n","\t1.0s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 170.65s of the 170.64s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.9364\t = Validation score   (accuracy)\r\n","\t0.85s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 169.67s of the 169.66s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.42%)\r\n","\t0.9\t = Validation score   (accuracy)\r\n","\t10.7s\t = Training   runtime\r\n","\t0.06s\t = Validation runtime\r\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 155.17s of the 155.16s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.9091\t = Validation score   (accuracy)\r\n","\t1.01s\t = Training   runtime\r\n","\t0.1s\t = Validation runtime\r\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 154.04s of the 154.03s of remaining time.\r\n","\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0\r\n","\t0.9182\t = Validation score   (accuracy)\r\n","\t0.86s\t = Training   runtime\r\n","\t0.11s\t = Validation runtime\r\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 153.05s of the 153.04s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.07%)\r\n","\t0.9364\t = Validation score   (accuracy)\r\n","\t5.49s\t = Training   runtime\r\n","\t0.04s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 143.53s of the 143.52s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.9182\t = Validation score   (accuracy)\r\n","\t22.64s\t = Training   runtime\r\n","\t0.14s\t = Validation runtime\r\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 116.35s of the 116.34s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.98%)\r\n","\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\r\n","\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21672, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Detailed Traceback:\r\n","Traceback (most recent call last):\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\r\n","    model = self._train_single(**model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\r\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\r\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\r\n","    self._fit_folds(\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\r\n","    fold_fitting_strategy.after_all_folds_scheduled()\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\r\n","    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\r\n","    self._process_fold_results(finished, unfinished, fold_ctx)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\r\n","    raise processed_exception\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\r\n","    out = self.ray.get(finished)\r\n","          ^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\r\n","    return fn(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\r\n","    return func(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2961, in get\r\n","    values, debugger_breakpoint = worker.get_objects(\r\n","                                  ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 1026, in get_objects\r\n","    raise value.as_instanceof_cause()\r\n","ray.exceptions.RayTaskError(KeyError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21672, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 106.69s of the 106.68s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.44%)\r\n","\t0.9091\t = Validation score   (accuracy)\r\n","\t10.73s\t = Training   runtime\r\n","\t0.06s\t = Validation runtime\r\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 92.05s of the 92.04s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.9273\t = Validation score   (accuracy)\r\n","\t20.44s\t = Training   runtime\r\n","\t0.2s\t = Validation runtime\r\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 67.24s of the 67.23s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.41%)\r\n","\tWarning: Exception caused LightGBM_r131_BAG_L1 to fail during training... Skipping this model.\r\n","\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22599, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Detailed Traceback:\r\n","Traceback (most recent call last):\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\r\n","    model = self._train_single(**model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\r\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\r\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\r\n","    self._fit_folds(\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\r\n","    fold_fitting_strategy.after_all_folds_scheduled()\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\r\n","    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\r\n","    self._process_fold_results(finished, unfinished, fold_ctx)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\r\n","    raise processed_exception\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\r\n","    out = self.ray.get(finished)\r\n","          ^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\r\n","    return fn(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\r\n","    return func(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2961, in get\r\n","    values, debugger_breakpoint = worker.get_objects(\r\n","                                  ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 1026, in get_objects\r\n","    raise value.as_instanceof_cause()\r\n","ray.exceptions.RayTaskError(KeyError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22599, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 57.82s of the 57.81s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\t0.9455\t = Validation score   (accuracy)\r\n","\t22.06s\t = Training   runtime\r\n","\t0.13s\t = Validation runtime\r\n","Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 31.70s of the 31.69s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.54%)\r\n","\t0.9182\t = Validation score   (accuracy)\r\n","\t13.02s\t = Training   runtime\r\n","\t0.05s\t = Validation runtime\r\n","Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 13.27s of the 13.26s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\r\n","\tWarning: Exception caused LightGBM_r96_BAG_L1 to fail during training... Skipping this model.\r\n","\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23523, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Detailed Traceback:\r\n","Traceback (most recent call last):\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2201, in _train_and_save\r\n","    model = self._train_single(**model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2085, in _train_single\r\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\r\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\r\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 393, in _fit\r\n","    self._fit_folds(\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 887, in _fit_folds\r\n","    fold_fitting_strategy.after_all_folds_scheduled()\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 796, in after_all_folds_scheduled\r\n","    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 713, in _run_parallel\r\n","    self._process_fold_results(finished, unfinished, fold_ctx)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 666, in _process_fold_results\r\n","    raise processed_exception\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 619, in _process_fold_results\r\n","    out = self.ray.get(finished)\r\n","          ^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\r\n","    return fn(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\r\n","    return func(*args, **kwargs)\r\n","           ^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 2961, in get\r\n","    values, debugger_breakpoint = worker.get_objects(\r\n","                                  ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py\", line 1026, in get_objects\r\n","    raise value.as_instanceof_cause()\r\n","ray.exceptions.RayTaskError(KeyError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23523, ip=172.19.2.2)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 473, in _ray_fit\r\n","    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1125, in fit\r\n","    out = self._fit(**kwargs)\r\n","          ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 215, in _fit\r\n","    dataset_train, dataset_val, dataset_test = self.generate_datasets(\r\n","                                               ^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 481, in generate_datasets\r\n","    X = self.preprocess(X, y=y, is_train=True)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 561, in preprocess\r\n","    X = self._preprocess_align_features(X, **kwargs)\r\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 567, in _preprocess_align_features\r\n","    X = X[self._features_internal_to_align]\r\n","        ~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\", line 4108, in __getitem__\r\n","    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6200, in _get_indexer_strict\r\n","    self._raise_if_missing(keyarr, indexer, axis_name)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 6249, in _raise_if_missing\r\n","    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\r\n","KeyError: \"None of [Index(['ID', 'Effort', 'AppExpr', 'IntComplx_4.0', 'DataOut_1.0', 'UFP_50.0',\\n       'Lang_C#,_ASP.Net_SQL', 'Lang_HTML,_PHP,_SQL', 'Lang_PHP',\\n       'Lang_html,_php,_sql,_proprietary', 'Tools_Notepad',\\n       'Tools_Visual_Studio.Net_2003,_Microsoft_SQL_Server_Enterprise_Manager/Query_Analyzer',\\n       'ToolExpr_[0,12]', 'ToolExpr_[0]', 'ToolExpr_[4,24]', 'DBMS_MySQL',\\n       'DBMS_SQLServer', 'DBMS_mysql', 'Method_OO'],\\n      dtype='object')] are in the [columns]\"\r\n","Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 5.41s of the 5.40s of remaining time.\r\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.00%)\r\n","\tTime limit exceeded... Skipping NeuralNetTorch_r22_BAG_L1.\r\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 212.61s of the -7.00s of remaining time.\r\n","\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.3 GB\r\n","\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\r\n","\t0.9455\t = Validation score   (accuracy)\r\n","\t0.13s\t = Training   runtime\r\n","\t0.0s\t = Validation runtime\r\n","AutoGluon training complete, total runtime = 219.77s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 116.4 rows/s (14 batch size)\r\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/autogluon_642170d3e5fe4314885cfdd051befec4\")\r\n","    ✓ {'imputation': 'most_frequent', 'scaling': 'minmax', 'encoding': 'onehot', 'outlier_removal': 'lof', 'dimensionality_reduction': 'none', 'feature_selection': 'mutual_info', 'step_order': ['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']} -> 0.8421\r\n","\r\n","Final recommendation\r\n","  Dataset: 1047\r\n","  Pipeline: {imputation=most_frequent, scaling=minmax, encoding=onehot, feature_selection=mutual_info, outlier_removal=lof, dimensionality_reduction=none, step_order=['imputation', 'scaling', 'encoding', 'outlier_removal', 'dimensionality_reduction', 'feature_selection']}\r\n","  Proxy score: 1.0000\r\n","  Final eval (autogluon): 0.8421\r\n","  Optimizer: aco\r\n","  Ordering search: strategy=heuristic orders=10\r\n","  Saved recommendation: /kaggle/working/dataset_1047/recommendation.json\r\n","  Saved ACO history: /kaggle/working/dataset_1047/aco_history.csv\r\n","  Saved ACO plot: /kaggle/working/dataset_1047/aco_progress.png\r\n","  Elapsed seconds: 1346.90\r\n","2026-02-25 04:17:44,246 | INFO | __main__ | Saved recommendation to /kaggle/working/dataset_1047/recommendation.json\r\n","\r\n","Aggregate summary\r\n","  Runs ok/failed: 2/0\r\n","  Avg elapsed seconds: 1276.40\r\n","  Avg proxy score: 0.9310\r\n","  Avg final score: 0.7831\r\n","  Avg autogluon score: 0.7831\r\n","\r\n","Saved multi-run summary: /kaggle/working/recommendations_summary.json\r\n","\u001b[0m"]}],"source":["# Commit 4\n","!python -m scripts.run_recommend \\\n","  --performance-matrix /kaggle/input/acorec/aco/training_performance_matrix_autogluon.csv \\\n","  --metafeatures /kaggle/input/acorec/aco/dataset_feats.csv \\\n","  --pipeline-configs /kaggle/input/acorec/aco/pipeline_configs.json \\\n","  --dataset-source openml \\\n","  --dataset-ids 1066, 1047 \\\n","  --use-aco \\\n","  --search-ordering \\\n","  --num-orders 10 \\\n","  --order-strategy heuristic \\\n","  --ordering-quick-time-limit 30 \\\n","  --seed 42 \\\n","  --n-ants 10 \\\n","  --n-iterations 10 \\\n","  --verbose\n"]},{"cell_type":"code","execution_count":null,"id":"3786583d","metadata":{"papermill":{"duration":0.180505,"end_time":"2026-02-25T04:17:49.825649","exception":false,"start_time":"2026-02-25T04:17:49.645144","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":13918325,"datasetId":8381793,"sourceId":13223565,"sourceType":"datasetVersion"},{"databundleVersionId":13946712,"datasetId":8395330,"sourceId":13249749,"sourceType":"datasetVersion"},{"databundleVersionId":13895196,"datasetId":8367218,"sourceId":13202526,"sourceType":"datasetVersion"},{"databundleVersionId":14038593,"datasetId":8453907,"sourceId":13333380,"sourceType":"datasetVersion"},{"databundleVersionId":13923003,"datasetId":8384633,"sourceId":13227831,"sourceType":"datasetVersion"},{"databundleVersionId":13891890,"datasetId":8363742,"sourceId":13199511,"sourceType":"datasetVersion"},{"databundleVersionId":15822721,"datasetId":9452976,"isSourceIdPinned":true,"sourceId":14952341,"sourceType":"datasetVersion"},{"databundleVersionId":15331670,"datasetId":9264728,"sourceId":14505601,"sourceType":"datasetVersion"},{"databundleVersionId":15304774,"datasetId":9249282,"sourceId":14481267,"sourceType":"datasetVersion"},{"databundleVersionId":14087326,"datasetId":8487747,"sourceId":13378082,"sourceType":"datasetVersion"},{"databundleVersionId":1320025,"datasetId":743713,"sourceId":1287930,"sourceType":"datasetVersion"},{"databundleVersionId":15306559,"datasetId":8786333,"isSourceIdPinned":true,"sourceId":14482880,"sourceType":"datasetVersion"}],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":2705.945019,"end_time":"2026-02-25T04:17:50.425121","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-25T03:32:44.480102","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}